{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"center\">Handwritten digits classification using neural network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us classify handwritten digits using \n",
    "1. A simple NN which has only input and output layers. \n",
    "2. NN with one hidden layer.\n",
    "3. NN with two hidden layers.\n",
    "\n",
    "and see how the performance of the model improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/MNIST-Handwritten digits.png\" height=450 width=450/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and split MNIST for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Handwritten digit MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/dataset.png\" height=450 width=450 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be something like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Figures/pixel.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]\n",
    "# Displays 28 x 28 pixels in 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c0a04dcca0>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]\n",
    "# Label for the above input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c0a057d940>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must convert this into 6000, 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28 * 28)\n",
    "X_train_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flattened = X_test.reshape(len(X_test),  28 * 28)\n",
    "X_test_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train_flattened / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized = X_test_flattened / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN model with one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Figures/model2.png\" height=400 width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # input layer 784 neurons to first hidden layer with 64 neurons\n",
    "    keras.layers.Dense(64, input_shape = (784,), activation='relu'), \n",
    "    # Previous hidden layer to output layer\n",
    "    keras.layers.Dense(10, activation='sigmoid')    \n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape = (784,), activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_188 (Dense)           (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x2c0a05bb430>,\n",
       " <keras.layers.core.dense.Dense at 0x2c0a05bb1f0>]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 35ms/step - loss: 2.1397 - accuracy: 0.2593\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.6485 - accuracy: 0.5891\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2389 - accuracy: 0.7230\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.9414 - accuracy: 0.7922\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.7460 - accuracy: 0.8233\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6198 - accuracy: 0.8475\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.5375 - accuracy: 0.8653\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.4818 - accuracy: 0.8765\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.4418 - accuracy: 0.8841\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.4120 - accuracy: 0.8911\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3884 - accuracy: 0.8961\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3694 - accuracy: 0.9015\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.3537 - accuracy: 0.9054\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3405 - accuracy: 0.9086\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3289 - accuracy: 0.9118\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3189 - accuracy: 0.9143\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3098 - accuracy: 0.9164\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3018 - accuracy: 0.9182\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2943 - accuracy: 0.9204\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.2876 - accuracy: 0.9221\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2814 - accuracy: 0.9235\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2755 - accuracy: 0.9248\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2699 - accuracy: 0.9266\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2647 - accuracy: 0.9279\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2599 - accuracy: 0.9289\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2553 - accuracy: 0.9307\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2508 - accuracy: 0.9317\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2465 - accuracy: 0.9329\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2424 - accuracy: 0.9338\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2385 - accuracy: 0.9347\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2349 - accuracy: 0.9361\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.2313 - accuracy: 0.9366\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2278 - accuracy: 0.9376\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.2244 - accuracy: 0.9388\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2209 - accuracy: 0.9394\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2177 - accuracy: 0.9402\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.2146 - accuracy: 0.9407\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.2116 - accuracy: 0.9418\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2087 - accuracy: 0.9429\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2059 - accuracy: 0.9432\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2031 - accuracy: 0.9442\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2004 - accuracy: 0.9445\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1979 - accuracy: 0.9453\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1953 - accuracy: 0.9462\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1927 - accuracy: 0.9468\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1903 - accuracy: 0.9475\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1880 - accuracy: 0.9477\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1857 - accuracy: 0.9485\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1835 - accuracy: 0.9493\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1812 - accuracy: 0.9499\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1791 - accuracy: 0.9506\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1770 - accuracy: 0.9511\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1749 - accuracy: 0.9513\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1729 - accuracy: 0.9524\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1709 - accuracy: 0.9529\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1689 - accuracy: 0.9532\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1670 - accuracy: 0.9539\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1652 - accuracy: 0.9543\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1634 - accuracy: 0.9549\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1616 - accuracy: 0.9554\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1597 - accuracy: 0.9556\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1580 - accuracy: 0.9560\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1564 - accuracy: 0.9566\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1549 - accuracy: 0.9571\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1531 - accuracy: 0.9575\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1515 - accuracy: 0.9581\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1499 - accuracy: 0.9582\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1483 - accuracy: 0.9592\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1468 - accuracy: 0.9595\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1454 - accuracy: 0.9599\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1439 - accuracy: 0.9605\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1424 - accuracy: 0.9606\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1409 - accuracy: 0.9610\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1395 - accuracy: 0.9618\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1382 - accuracy: 0.9620\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1367 - accuracy: 0.9624\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1354 - accuracy: 0.9629\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1340 - accuracy: 0.9632\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1326 - accuracy: 0.9638\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1314 - accuracy: 0.9638\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1302 - accuracy: 0.9642\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1289 - accuracy: 0.9645\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1278 - accuracy: 0.9647\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1264 - accuracy: 0.9651\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1252 - accuracy: 0.9655\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1241 - accuracy: 0.9655\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1228 - accuracy: 0.9658\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1217 - accuracy: 0.9662\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1206 - accuracy: 0.9667\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1194 - accuracy: 0.9669\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1184 - accuracy: 0.9669\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1173 - accuracy: 0.9675\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1163 - accuracy: 0.9677\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.1152 - accuracy: 0.9680\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1142 - accuracy: 0.9682\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1134 - accuracy: 0.9683\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1125 - accuracy: 0.9685\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1113 - accuracy: 0.9691\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1103 - accuracy: 0.9694\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1094 - accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c0a05b4f40>"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_normalized, y_train, epochs = 100, verbose=1, batch_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting weights and bias values after the training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-404-4f8fb3d8cc7f>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  weights = np.array(original_weights)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([[ 0.03313845, -0.05806822, -0.06300296, ..., -0.0628145 ,\n",
       "                0.00584284, -0.03571126],\n",
       "              [ 0.05299837, -0.07606329,  0.07917354, ...,  0.02267645,\n",
       "                0.08102488,  0.07239794],\n",
       "              [-0.03857384, -0.04556585, -0.01038469, ...,  0.00685869,\n",
       "                0.02624539, -0.0532121 ],\n",
       "              ...,\n",
       "              [ 0.05094124, -0.07877113, -0.08311564, ..., -0.02148538,\n",
       "               -0.07875767,  0.06038708],\n",
       "              [-0.04329074, -0.01596504,  0.08128626, ..., -0.03404623,\n",
       "                0.04891136,  0.08062259],\n",
       "              [ 0.05455414, -0.0238579 , -0.05515278, ..., -0.07196478,\n",
       "                0.08281463,  0.02076405]], dtype=float32)              ,\n",
       "       array([ 0.05232109,  0.08736482, -0.08231933,  0.01211582,  0.00458064,\n",
       "               0.03812985,  0.16841695,  0.01041508,  0.02917773,  0.04843887,\n",
       "               0.20593856,  0.0232954 ,  0.11044628, -0.03851435, -0.00929046,\n",
       "               0.02504925,  0.04867984, -0.0160343 ,  0.0625328 ,  0.11035717,\n",
       "               0.02140745, -0.0450017 ,  0.05870792,  0.0780674 ,  0.05065313,\n",
       "               0.05217264,  0.03214836,  0.05520001, -0.0577762 ,  0.12832502,\n",
       "               0.0573783 ,  0.20155184, -0.08349374,  0.08398577, -0.02551393,\n",
       "              -0.04493155,  0.06416006, -0.00933366,  0.05196128, -0.03291681,\n",
       "              -0.03734412,  0.02055074,  0.01338655, -0.12397888,  0.03296715,\n",
       "              -0.0834765 ,  0.06671446, -0.04816326, -0.04621329,  0.00470987,\n",
       "              -0.0578814 ,  0.0647288 , -0.01923519,  0.04551282,  0.03181357,\n",
       "              -0.06914335,  0.06330365,  0.04253759,  0.08764268, -0.00964639,\n",
       "               0.00395405,  0.02047261,  0.10625917,  0.09375841], dtype=float32),\n",
       "       array([[-3.09624046e-01,  8.24916884e-02,  8.22237357e-02,\n",
       "               -2.28904963e-01,  2.50713557e-01, -6.75480142e-02,\n",
       "                3.57565403e-01,  1.45755351e-01, -1.86024621e-01,\n",
       "                2.26056114e-01],\n",
       "              [-4.49724555e-01,  3.87801588e-01, -4.49951231e-01,\n",
       "               -5.56913972e-01,  8.77468288e-03,  3.04637790e-01,\n",
       "                2.69348264e-01, -1.41604751e-01, -3.62319261e-01,\n",
       "                2.04117909e-01],\n",
       "              [ 3.20476681e-01,  1.19318068e-01,  2.64397532e-01,\n",
       "               -2.46136889e-01,  8.43825266e-02, -5.91564596e-01,\n",
       "                2.25835696e-01, -3.00781369e-01, -4.47164267e-01,\n",
       "                4.01692390e-01],\n",
       "              [ 5.14119640e-02,  3.89341116e-01, -3.45448226e-01,\n",
       "                2.92563051e-01,  2.98921555e-01, -6.05802000e-01,\n",
       "               -7.25607872e-02,  2.73730487e-01, -1.22641370e-01,\n",
       "               -2.16751724e-01],\n",
       "              [ 4.73080009e-01, -2.35821962e-01, -4.90836501e-02,\n",
       "               -2.57490762e-02,  3.14414829e-01, -1.11421354e-01,\n",
       "                1.56887040e-01,  3.03242445e-01, -5.98548770e-01,\n",
       "                6.88060597e-02],\n",
       "              [-1.10537978e-02, -2.91273117e-01, -1.62486266e-02,\n",
       "               -2.66226947e-01,  3.33893836e-01,  3.89051706e-01,\n",
       "               -2.65624076e-01, -4.04885530e-01,  1.37348682e-01,\n",
       "               -3.30512747e-02],\n",
       "              [ 2.96805292e-01,  9.99539942e-02,  2.10224688e-02,\n",
       "                1.20127402e-01, -1.01046771e-01,  4.77609128e-01,\n",
       "               -1.27990395e-01,  3.71943563e-01, -7.09763467e-01,\n",
       "               -2.67560840e-01],\n",
       "              [-2.35068798e-01,  1.19870752e-01,  2.63184041e-01,\n",
       "                3.56353104e-01, -2.48021752e-01, -3.69848937e-01,\n",
       "               -2.19950750e-01,  1.95889518e-01,  1.05673276e-01,\n",
       "                3.89153749e-01],\n",
       "              [-2.52808958e-01,  5.93536384e-02,  3.10569793e-01,\n",
       "               -1.58905074e-01, -6.09269626e-02, -1.50359184e-01,\n",
       "               -1.87651128e-01, -7.66476691e-02,  1.39726654e-01,\n",
       "                9.29563716e-02],\n",
       "              [ 1.03421837e-01,  2.72726834e-01, -2.83713162e-01,\n",
       "               -3.02346766e-01, -4.33758795e-02, -1.67715505e-01,\n",
       "                1.10162251e-01,  7.81596079e-02, -4.70316350e-01,\n",
       "                3.08175273e-02],\n",
       "              [ 3.73614460e-01,  5.82315564e-01, -1.58466888e-03,\n",
       "               -3.08021218e-01, -5.07844627e-01,  5.54461718e-01,\n",
       "                1.14335716e-01,  2.01961502e-01, -5.89747190e-01,\n",
       "               -4.86280650e-01],\n",
       "              [-3.45988721e-01,  3.59363675e-01,  3.40927213e-01,\n",
       "               -3.13500226e-01,  2.69252479e-01, -3.74960065e-01,\n",
       "                1.83446273e-01,  2.92226851e-01,  2.22781539e-01,\n",
       "               -5.92525244e-01],\n",
       "              [-2.44118214e-01, -2.84451246e-01, -1.29381632e-02,\n",
       "               -8.52116272e-02,  2.00750843e-01,  2.64527410e-01,\n",
       "               -3.44461948e-01,  4.65254009e-01, -5.50620615e-01,\n",
       "                1.86608210e-01],\n",
       "              [ 1.28831372e-01, -4.97476794e-02, -3.83637995e-01,\n",
       "                2.93165475e-01, -3.48415524e-01,  1.23546766e-02,\n",
       "               -3.39840382e-01, -8.76848251e-02,  2.54893243e-01,\n",
       "                3.34129661e-01],\n",
       "              [ 3.47637869e-02, -1.18116848e-03,  1.58476025e-01,\n",
       "                4.37682450e-01, -3.22114766e-01, -2.30293185e-01,\n",
       "                2.06664532e-01, -2.37299263e-01, -3.48563343e-01,\n",
       "               -4.27984804e-01],\n",
       "              [-2.16186211e-01,  3.03610340e-02,  1.82421014e-01,\n",
       "               -1.04080468e-01, -8.06351453e-02, -4.63218808e-01,\n",
       "               -2.25359693e-01,  3.41251373e-01,  2.07673937e-01,\n",
       "                3.94870579e-01],\n",
       "              [ 6.53417632e-02,  3.32143515e-01, -5.74865699e-01,\n",
       "               -6.29766434e-02, -4.16729003e-02, -5.91824166e-02,\n",
       "                1.99755058e-01,  9.12747160e-02, -2.93162107e-01,\n",
       "               -5.04957736e-01],\n",
       "              [ 1.73743337e-01, -2.85071522e-01,  5.25880575e-01,\n",
       "                7.51482025e-02,  4.91968766e-02, -3.97265583e-01,\n",
       "               -3.40698808e-01,  1.39140815e-01, -7.17521429e-01,\n",
       "                2.37808198e-01],\n",
       "              [ 1.60338834e-01,  8.26464891e-02,  1.86786160e-01,\n",
       "               -2.12603241e-01,  3.60483490e-02,  2.49208525e-01,\n",
       "                3.77216429e-01, -1.77609786e-01,  2.25256026e-01,\n",
       "               -3.40631098e-01],\n",
       "              [-3.73931617e-01,  1.56290755e-01,  8.62107053e-02,\n",
       "               -1.17732309e-01, -5.40113509e-01,  3.71964097e-01,\n",
       "               -3.49969149e-01, -1.76366553e-01, -2.17170477e-01,\n",
       "                2.36068755e-01],\n",
       "              [-3.77941608e-01, -1.43256024e-01,  3.49244446e-01,\n",
       "                3.55410159e-01,  5.30585647e-02, -2.06549689e-01,\n",
       "                2.74571657e-01, -3.73746872e-01, -1.45345896e-01,\n",
       "                1.03128999e-02],\n",
       "              [-2.50516266e-01, -9.62560847e-02, -1.59343615e-01,\n",
       "                3.48100036e-01, -1.25904754e-01, -4.35164534e-02,\n",
       "               -3.09185416e-01, -3.70212317e-01, -7.59672225e-02,\n",
       "                4.31984633e-01],\n",
       "              [-3.17018456e-03,  6.44137800e-01, -3.29990625e-01,\n",
       "               -3.38859349e-01,  5.68899035e-01,  2.53043026e-01,\n",
       "                2.30194271e-01,  1.02516539e-01, -4.08527046e-01,\n",
       "               -7.04031765e-01],\n",
       "              [-3.37742031e-01,  9.67588797e-02, -1.79794043e-01,\n",
       "                2.73333251e-01, -3.32955927e-01,  2.15615723e-02,\n",
       "               -2.83269346e-01, -3.33337635e-01, -1.10846058e-01,\n",
       "               -3.45938295e-01],\n",
       "              [-4.45826985e-02, -4.15382087e-01,  8.69467705e-02,\n",
       "               -1.67710721e-01, -3.54705364e-01,  1.43309027e-01,\n",
       "                2.69045413e-01,  3.45811546e-01,  3.17790985e-01,\n",
       "                1.51531622e-01],\n",
       "              [ 2.03828990e-01, -2.75417298e-01, -3.38218398e-02,\n",
       "               -1.49800152e-01, -7.24542961e-02,  3.61191273e-01,\n",
       "                7.84174353e-03, -2.16635600e-01, -3.79352808e-01,\n",
       "                2.81094462e-01],\n",
       "              [-1.56479399e-03, -4.42146897e-01,  5.21478355e-01,\n",
       "               -4.09246773e-01,  2.74094403e-01, -2.51080126e-01,\n",
       "                2.78179199e-01,  1.21002682e-01, -1.61168009e-01,\n",
       "               -5.98928750e-01],\n",
       "              [ 6.49437085e-02,  9.03769061e-02, -2.11768612e-01,\n",
       "                1.29557222e-01, -1.07732955e-02,  3.16589385e-01,\n",
       "                6.17802795e-03, -3.48721415e-01,  1.68631777e-01,\n",
       "               -2.78621584e-01],\n",
       "              [-2.31918499e-01,  1.99966747e-02,  3.45343977e-01,\n",
       "                3.66104484e-01, -1.73348621e-01,  4.22983468e-02,\n",
       "               -1.97019383e-01,  2.01910302e-01,  1.01383319e-02,\n",
       "               -3.57325882e-01],\n",
       "              [-4.00657624e-01,  3.91530335e-01,  6.21846020e-02,\n",
       "                3.89420360e-01,  3.76381487e-01,  2.55831271e-01,\n",
       "                2.23686174e-01,  2.42455184e-01,  2.28150144e-01,\n",
       "               -4.01010275e-01],\n",
       "              [-3.03009033e-01, -4.98542428e-01, -2.45064311e-02,\n",
       "               -2.35143870e-01,  2.57429957e-01, -2.54920512e-01,\n",
       "                2.80610085e-01,  3.09834540e-01, -7.05896541e-02,\n",
       "                2.37567991e-01],\n",
       "              [-4.76067424e-01, -2.86456615e-01, -4.11856361e-02,\n",
       "                2.79114217e-01,  3.78461450e-01,  5.02296805e-01,\n",
       "               -5.27147889e-01,  4.04868454e-01, -5.70086017e-02,\n",
       "               -2.39601731e-01],\n",
       "              [ 2.01127809e-02, -1.52301624e-01,  5.22508658e-02,\n",
       "               -1.00637518e-01, -1.18582912e-01, -3.47098529e-01,\n",
       "               -2.46620297e-01,  6.24301508e-02,  3.83241385e-01,\n",
       "                2.68657804e-01],\n",
       "              [-1.51140541e-01,  2.52623528e-01,  4.72929537e-01,\n",
       "                9.84304696e-02, -7.57360011e-02, -3.71847928e-01,\n",
       "               -3.40061218e-01,  4.51514244e-01, -4.75326806e-01,\n",
       "               -5.23780882e-01],\n",
       "              [-3.57148826e-01, -2.33925924e-01,  4.03262407e-01,\n",
       "               -6.56046867e-02,  7.46326149e-02, -7.95705989e-02,\n",
       "                3.28174412e-01, -6.13738835e-01,  1.45329475e-01,\n",
       "                2.70507365e-01],\n",
       "              [-1.06958048e-02,  1.41790286e-01, -8.07811469e-02,\n",
       "                2.37696748e-02,  3.10676098e-01, -2.49038428e-01,\n",
       "               -2.48506606e-01, -2.59281993e-02,  3.74992639e-01,\n",
       "               -2.27617323e-01],\n",
       "              [-3.93061578e-01,  2.95888364e-01, -1.16251037e-01,\n",
       "                2.75144368e-01, -3.89202446e-01,  4.50907409e-01,\n",
       "               -2.71580487e-01,  1.18411727e-01, -1.25301197e-01,\n",
       "                1.46302998e-01],\n",
       "              [-1.98323876e-02,  9.05673429e-02,  2.99698580e-02,\n",
       "                2.97917034e-02, -4.93039221e-01, -1.50479704e-01,\n",
       "               -2.78299451e-01,  1.32951155e-01,  1.02781318e-01,\n",
       "               -3.43764991e-01],\n",
       "              [ 1.82323530e-01, -9.79615748e-02,  1.52572721e-01,\n",
       "                1.28593937e-01, -3.54291916e-01, -1.84921116e-01,\n",
       "               -4.09006417e-01,  1.15925513e-01, -2.85652608e-01,\n",
       "                7.49829262e-02],\n",
       "              [-5.10556041e-04,  3.99349891e-02, -4.97814029e-01,\n",
       "                3.74561958e-02,  3.42344195e-01, -3.79041612e-01,\n",
       "                2.34946519e-01, -6.34966493e-02,  2.28277132e-01,\n",
       "                1.15312800e-01],\n",
       "              [ 2.29081407e-01, -3.77110243e-01,  9.49671119e-02,\n",
       "                3.49100322e-01,  2.60815889e-01, -3.85622829e-02,\n",
       "               -2.12433740e-01, -2.32121393e-01,  3.77758103e-03,\n",
       "               -2.17938080e-01],\n",
       "              [ 4.89219800e-02, -1.51989877e-01,  4.72333133e-01,\n",
       "               -3.24818432e-01,  1.90289214e-01,  2.54065365e-01,\n",
       "                1.11090779e-01, -3.32242548e-01,  3.20684671e-01,\n",
       "               -5.67316949e-01],\n",
       "              [-1.05411120e-01,  2.93170065e-01,  2.50095040e-01,\n",
       "               -2.88334578e-01,  1.11773707e-01, -1.99113488e-01,\n",
       "                3.32595110e-01, -2.53500581e-01,  9.91835445e-02,\n",
       "                1.84151173e-01],\n",
       "              [ 3.38400245e-01, -4.23072845e-01, -2.22313568e-01,\n",
       "               -2.00001150e-02, -9.15861223e-03, -1.31229103e-01,\n",
       "                8.89282383e-04,  5.42177521e-02,  3.17107856e-01,\n",
       "                2.67627954e-01],\n",
       "              [-2.73690403e-01, -1.60902590e-01,  3.73680115e-01,\n",
       "               -1.30369574e-01,  2.67297506e-01, -1.46918431e-01,\n",
       "               -1.74559325e-01, -5.10306120e-01, -3.23404133e-01,\n",
       "                1.60691768e-01],\n",
       "              [ 2.40175650e-01,  3.26757953e-02, -5.42791367e-01,\n",
       "                3.53669375e-01,  2.43469894e-01, -2.90832907e-01,\n",
       "                2.67547280e-01, -2.25498877e-03, -5.96776307e-01,\n",
       "               -1.29638640e-02],\n",
       "              [-3.21480840e-01,  3.02501380e-01,  1.19915396e-01,\n",
       "               -5.50925016e-01, -1.63202971e-01,  3.89874801e-02,\n",
       "                3.78953934e-01,  7.32192174e-02,  4.25233662e-01,\n",
       "                4.36695784e-01],\n",
       "              [-2.37053439e-01,  1.18498974e-01,  2.94523329e-01,\n",
       "               -2.20636711e-01,  3.98885071e-01, -4.26504880e-01,\n",
       "               -2.37727851e-01, -3.67992669e-01,  1.65234372e-01,\n",
       "               -2.25375503e-01],\n",
       "              [ 5.92879131e-02, -3.43094707e-01, -7.05549270e-02,\n",
       "                1.07465729e-01, -3.45314354e-01,  2.51259893e-01,\n",
       "                1.00279070e-01, -3.23472470e-01,  1.14068747e-01,\n",
       "                2.81125847e-02],\n",
       "              [ 2.27062702e-01, -1.85638070e-01,  2.84716308e-01,\n",
       "               -2.44559735e-01,  2.17170656e-01,  3.02870303e-01,\n",
       "                3.17884445e-01, -3.82624894e-01,  2.88320512e-01,\n",
       "               -2.67998695e-01],\n",
       "              [ 1.93267226e-01, -7.66182989e-02, -1.96476072e-01,\n",
       "               -2.99555779e-01,  1.91588372e-01, -3.60132664e-01,\n",
       "                2.32229218e-01, -4.27172601e-01, -1.15354098e-01,\n",
       "                1.19236521e-01],\n",
       "              [ 3.01368356e-01, -1.07779764e-01,  2.47329950e-01,\n",
       "               -1.56707168e-01,  7.42278248e-02, -8.04355815e-02,\n",
       "               -1.56058464e-02,  3.30803692e-01, -1.69016510e-01,\n",
       "               -1.25567168e-01],\n",
       "              [ 1.50815964e-01, -4.25956637e-01, -1.23981826e-01,\n",
       "                3.08686256e-01, -2.44154170e-01,  3.20743740e-01,\n",
       "               -2.61495411e-01, -8.16578865e-02,  1.16406307e-01,\n",
       "                2.25146022e-03],\n",
       "              [-4.15556610e-01, -2.34645337e-01, -1.75019816e-01,\n",
       "                2.27042019e-01,  3.76955062e-01,  2.99870253e-01,\n",
       "               -2.71735311e-01, -4.03605580e-01, -9.71715674e-02,\n",
       "                1.09709308e-01],\n",
       "              [ 2.88964808e-01,  1.54643178e-01, -1.60439268e-01,\n",
       "               -2.57845391e-02, -1.64138898e-01,  3.41192573e-01,\n",
       "               -7.47580035e-03, -2.87610561e-01,  3.74580801e-01,\n",
       "               -2.89159477e-01],\n",
       "              [ 3.19738150e-01, -1.78086728e-01, -6.77011311e-01,\n",
       "               -5.31910002e-01,  3.54022235e-01,  6.56543911e-01,\n",
       "                5.38632870e-01, -4.02313098e-02,  1.78396448e-01,\n",
       "                4.31196868e-01],\n",
       "              [-1.21933676e-01, -2.32381642e-01, -3.01753074e-01,\n",
       "               -9.81894806e-02,  8.12126249e-02, -2.22183421e-01,\n",
       "               -2.58256972e-01,  3.59389305e-01,  4.73003946e-02,\n",
       "               -1.87896490e-01],\n",
       "              [-2.49939337e-01,  1.93758115e-01, -1.84998121e-02,\n",
       "                3.75590920e-01, -4.19763088e-01,  3.11759979e-01,\n",
       "                7.88322762e-02, -1.55780435e-01,  1.96087167e-01,\n",
       "               -9.26010460e-02],\n",
       "              [-2.29832023e-01,  2.30303973e-01,  2.40766108e-01,\n",
       "               -4.20085907e-01,  2.53826916e-01, -4.10051078e-01,\n",
       "               -3.00281882e-01,  1.18122995e-01, -8.66435543e-02,\n",
       "                2.26044744e-01],\n",
       "              [ 1.33068174e-01, -1.94535971e-01, -3.73350531e-01,\n",
       "                3.91290665e-01,  6.93719313e-02,  4.46157455e-01,\n",
       "               -1.85822379e-02, -1.65236473e-01, -2.19115298e-02,\n",
       "                3.78894210e-01],\n",
       "              [ 3.71570200e-01,  4.19926383e-02,  2.49293774e-01,\n",
       "                4.92540374e-02, -2.49597669e-01,  4.23359172e-03,\n",
       "               -7.72310123e-02, -2.13001624e-01, -2.08376899e-01,\n",
       "               -1.97336942e-01],\n",
       "              [ 3.44299138e-01,  4.97556813e-02, -1.55044675e-01,\n",
       "               -4.27618027e-01,  9.69497263e-02, -2.56742597e-01,\n",
       "                1.63737193e-01,  4.67685223e-01, -3.54938060e-02,\n",
       "               -1.84476282e-02],\n",
       "              [-3.33008051e-01,  4.35308367e-02, -2.00464010e-01,\n",
       "               -6.51526526e-02,  6.16625287e-02,  1.21383794e-01,\n",
       "               -2.83721328e-01,  3.22285622e-01, -3.19714457e-01,\n",
       "                6.99468851e-02],\n",
       "              [ 2.14263320e-01, -1.91416647e-02,  2.53532201e-01,\n",
       "                1.53551579e-01, -8.82375911e-02,  3.84843200e-02,\n",
       "                1.56375710e-02,  4.06486273e-01, -3.99088383e-01,\n",
       "               -3.41132015e-01]], dtype=float32)                 ,\n",
       "       array([-0.12543269,  0.06943326,  0.02147546, -0.03645208, -0.00770996,\n",
       "               0.11889728, -0.06301852,  0.08854801, -0.10084939, -0.01300905],\n",
       "             dtype=float32)                                                    ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_weights = model.get_weights()\n",
    "# convert list to array\n",
    "weights = np.array(original_weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 64)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights of first layer\n",
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias of first layer\n",
    "weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights of second layer\n",
    "weights[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias of second layer\n",
    "weights[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03313845, -0.05806822, -0.06300296, ..., -0.0628145 ,\n",
       "         0.00584284, -0.03571126],\n",
       "       [ 0.05299837, -0.07606329,  0.07917354, ...,  0.02267645,\n",
       "         0.08102488,  0.07239794],\n",
       "       [-0.03857384, -0.04556585, -0.01038469, ...,  0.00685869,\n",
       "         0.02624539, -0.0532121 ],\n",
       "       ...,\n",
       "       [ 0.05094124, -0.07877113, -0.08311564, ..., -0.02148538,\n",
       "        -0.07875767,  0.06038708],\n",
       "       [-0.04329074, -0.01596504,  0.08128626, ..., -0.03404623,\n",
       "         0.04891136,  0.08062259],\n",
       "       [ 0.05455414, -0.0238579 , -0.05515278, ..., -0.07196478,\n",
       "         0.08281463,  0.02076405]], dtype=float32)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.03313845, -0.05806822, -0.06300296, ..., -0.0628145 ,\n",
       "          0.00584284, -0.03571126],\n",
       "        [ 0.05299837, -0.07606329,  0.07917354, ...,  0.02267645,\n",
       "          0.08102488,  0.07239794],\n",
       "        [-0.03857384, -0.04556585, -0.01038469, ...,  0.00685869,\n",
       "          0.02624539, -0.0532121 ],\n",
       "        ...,\n",
       "        [ 0.05094124, -0.07877113, -0.08311564, ..., -0.02148538,\n",
       "         -0.07875767,  0.06038708],\n",
       "        [-0.04329074, -0.01596504,  0.08128626, ..., -0.03404623,\n",
       "          0.04891136,  0.08062259],\n",
       "        [ 0.05455414, -0.0238579 , -0.05515278, ..., -0.07196478,\n",
       "          0.08281463,  0.02076405]], dtype=float32),\n",
       " array([ 0.05232109,  0.08736482, -0.08231933,  0.01211582,  0.00458064,\n",
       "         0.03812985,  0.16841695,  0.01041508,  0.02917773,  0.04843887,\n",
       "         0.20593856,  0.0232954 ,  0.11044628, -0.03851435, -0.00929046,\n",
       "         0.02504925,  0.04867984, -0.0160343 ,  0.0625328 ,  0.11035717,\n",
       "         0.02140745, -0.0450017 ,  0.05870792,  0.0780674 ,  0.05065313,\n",
       "         0.05217264,  0.03214836,  0.05520001, -0.0577762 ,  0.12832502,\n",
       "         0.0573783 ,  0.20155184, -0.08349374,  0.08398577, -0.02551393,\n",
       "        -0.04493155,  0.06416006, -0.00933366,  0.05196128, -0.03291681,\n",
       "        -0.03734412,  0.02055074,  0.01338655, -0.12397888,  0.03296715,\n",
       "        -0.0834765 ,  0.06671446, -0.04816326, -0.04621329,  0.00470987,\n",
       "        -0.0578814 ,  0.0647288 , -0.01923519,  0.04551282,  0.03181357,\n",
       "        -0.06914335,  0.06330365,  0.04253759,  0.08764268, -0.00964639,\n",
       "         0.00395405,  0.02047261,  0.10625917,  0.09375841], dtype=float32)]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()\n",
    "# displays the weights and biases of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03313845, -0.05806822, -0.06300296, ..., -0.0628145 ,\n",
       "         0.00584284, -0.03571126],\n",
       "       [ 0.05299837, -0.07606329,  0.07917354, ...,  0.02267645,\n",
       "         0.08102488,  0.07239794],\n",
       "       [-0.03857384, -0.04556585, -0.01038469, ...,  0.00685869,\n",
       "         0.02624539, -0.0532121 ],\n",
       "       ...,\n",
       "       [ 0.05094124, -0.07877113, -0.08311564, ..., -0.02148538,\n",
       "        -0.07875767,  0.06038708],\n",
       "       [-0.04329074, -0.01596504,  0.08128626, ..., -0.03404623,\n",
       "         0.04891136,  0.08062259],\n",
       "       [ 0.05455414, -0.0238579 , -0.05515278, ..., -0.07196478,\n",
       "         0.08281463,  0.02076405]], dtype=float32)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0]\n",
    "# Displays the weights of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05232109,  0.08736482, -0.08231933,  0.01211582,  0.00458064,\n",
       "        0.03812985,  0.16841695,  0.01041508,  0.02917773,  0.04843887,\n",
       "        0.20593856,  0.0232954 ,  0.11044628, -0.03851435, -0.00929046,\n",
       "        0.02504925,  0.04867984, -0.0160343 ,  0.0625328 ,  0.11035717,\n",
       "        0.02140745, -0.0450017 ,  0.05870792,  0.0780674 ,  0.05065313,\n",
       "        0.05217264,  0.03214836,  0.05520001, -0.0577762 ,  0.12832502,\n",
       "        0.0573783 ,  0.20155184, -0.08349374,  0.08398577, -0.02551393,\n",
       "       -0.04493155,  0.06416006, -0.00933366,  0.05196128, -0.03291681,\n",
       "       -0.03734412,  0.02055074,  0.01338655, -0.12397888,  0.03296715,\n",
       "       -0.0834765 ,  0.06671446, -0.04816326, -0.04621329,  0.00470987,\n",
       "       -0.0578814 ,  0.0647288 , -0.01923519,  0.04551282,  0.03181357,\n",
       "       -0.06914335,  0.06330365,  0.04253759,  0.08764268, -0.00964639,\n",
       "        0.00395405,  0.02047261,  0.10625917,  0.09375841], dtype=float32)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[1]\n",
    "# Displays the biases of first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.09624046e-01,  8.24916884e-02,  8.22237357e-02,\n",
       "         -2.28904963e-01,  2.50713557e-01, -6.75480142e-02,\n",
       "          3.57565403e-01,  1.45755351e-01, -1.86024621e-01,\n",
       "          2.26056114e-01],\n",
       "        [-4.49724555e-01,  3.87801588e-01, -4.49951231e-01,\n",
       "         -5.56913972e-01,  8.77468288e-03,  3.04637790e-01,\n",
       "          2.69348264e-01, -1.41604751e-01, -3.62319261e-01,\n",
       "          2.04117909e-01],\n",
       "        [ 3.20476681e-01,  1.19318068e-01,  2.64397532e-01,\n",
       "         -2.46136889e-01,  8.43825266e-02, -5.91564596e-01,\n",
       "          2.25835696e-01, -3.00781369e-01, -4.47164267e-01,\n",
       "          4.01692390e-01],\n",
       "        [ 5.14119640e-02,  3.89341116e-01, -3.45448226e-01,\n",
       "          2.92563051e-01,  2.98921555e-01, -6.05802000e-01,\n",
       "         -7.25607872e-02,  2.73730487e-01, -1.22641370e-01,\n",
       "         -2.16751724e-01],\n",
       "        [ 4.73080009e-01, -2.35821962e-01, -4.90836501e-02,\n",
       "         -2.57490762e-02,  3.14414829e-01, -1.11421354e-01,\n",
       "          1.56887040e-01,  3.03242445e-01, -5.98548770e-01,\n",
       "          6.88060597e-02],\n",
       "        [-1.10537978e-02, -2.91273117e-01, -1.62486266e-02,\n",
       "         -2.66226947e-01,  3.33893836e-01,  3.89051706e-01,\n",
       "         -2.65624076e-01, -4.04885530e-01,  1.37348682e-01,\n",
       "         -3.30512747e-02],\n",
       "        [ 2.96805292e-01,  9.99539942e-02,  2.10224688e-02,\n",
       "          1.20127402e-01, -1.01046771e-01,  4.77609128e-01,\n",
       "         -1.27990395e-01,  3.71943563e-01, -7.09763467e-01,\n",
       "         -2.67560840e-01],\n",
       "        [-2.35068798e-01,  1.19870752e-01,  2.63184041e-01,\n",
       "          3.56353104e-01, -2.48021752e-01, -3.69848937e-01,\n",
       "         -2.19950750e-01,  1.95889518e-01,  1.05673276e-01,\n",
       "          3.89153749e-01],\n",
       "        [-2.52808958e-01,  5.93536384e-02,  3.10569793e-01,\n",
       "         -1.58905074e-01, -6.09269626e-02, -1.50359184e-01,\n",
       "         -1.87651128e-01, -7.66476691e-02,  1.39726654e-01,\n",
       "          9.29563716e-02],\n",
       "        [ 1.03421837e-01,  2.72726834e-01, -2.83713162e-01,\n",
       "         -3.02346766e-01, -4.33758795e-02, -1.67715505e-01,\n",
       "          1.10162251e-01,  7.81596079e-02, -4.70316350e-01,\n",
       "          3.08175273e-02],\n",
       "        [ 3.73614460e-01,  5.82315564e-01, -1.58466888e-03,\n",
       "         -3.08021218e-01, -5.07844627e-01,  5.54461718e-01,\n",
       "          1.14335716e-01,  2.01961502e-01, -5.89747190e-01,\n",
       "         -4.86280650e-01],\n",
       "        [-3.45988721e-01,  3.59363675e-01,  3.40927213e-01,\n",
       "         -3.13500226e-01,  2.69252479e-01, -3.74960065e-01,\n",
       "          1.83446273e-01,  2.92226851e-01,  2.22781539e-01,\n",
       "         -5.92525244e-01],\n",
       "        [-2.44118214e-01, -2.84451246e-01, -1.29381632e-02,\n",
       "         -8.52116272e-02,  2.00750843e-01,  2.64527410e-01,\n",
       "         -3.44461948e-01,  4.65254009e-01, -5.50620615e-01,\n",
       "          1.86608210e-01],\n",
       "        [ 1.28831372e-01, -4.97476794e-02, -3.83637995e-01,\n",
       "          2.93165475e-01, -3.48415524e-01,  1.23546766e-02,\n",
       "         -3.39840382e-01, -8.76848251e-02,  2.54893243e-01,\n",
       "          3.34129661e-01],\n",
       "        [ 3.47637869e-02, -1.18116848e-03,  1.58476025e-01,\n",
       "          4.37682450e-01, -3.22114766e-01, -2.30293185e-01,\n",
       "          2.06664532e-01, -2.37299263e-01, -3.48563343e-01,\n",
       "         -4.27984804e-01],\n",
       "        [-2.16186211e-01,  3.03610340e-02,  1.82421014e-01,\n",
       "         -1.04080468e-01, -8.06351453e-02, -4.63218808e-01,\n",
       "         -2.25359693e-01,  3.41251373e-01,  2.07673937e-01,\n",
       "          3.94870579e-01],\n",
       "        [ 6.53417632e-02,  3.32143515e-01, -5.74865699e-01,\n",
       "         -6.29766434e-02, -4.16729003e-02, -5.91824166e-02,\n",
       "          1.99755058e-01,  9.12747160e-02, -2.93162107e-01,\n",
       "         -5.04957736e-01],\n",
       "        [ 1.73743337e-01, -2.85071522e-01,  5.25880575e-01,\n",
       "          7.51482025e-02,  4.91968766e-02, -3.97265583e-01,\n",
       "         -3.40698808e-01,  1.39140815e-01, -7.17521429e-01,\n",
       "          2.37808198e-01],\n",
       "        [ 1.60338834e-01,  8.26464891e-02,  1.86786160e-01,\n",
       "         -2.12603241e-01,  3.60483490e-02,  2.49208525e-01,\n",
       "          3.77216429e-01, -1.77609786e-01,  2.25256026e-01,\n",
       "         -3.40631098e-01],\n",
       "        [-3.73931617e-01,  1.56290755e-01,  8.62107053e-02,\n",
       "         -1.17732309e-01, -5.40113509e-01,  3.71964097e-01,\n",
       "         -3.49969149e-01, -1.76366553e-01, -2.17170477e-01,\n",
       "          2.36068755e-01],\n",
       "        [-3.77941608e-01, -1.43256024e-01,  3.49244446e-01,\n",
       "          3.55410159e-01,  5.30585647e-02, -2.06549689e-01,\n",
       "          2.74571657e-01, -3.73746872e-01, -1.45345896e-01,\n",
       "          1.03128999e-02],\n",
       "        [-2.50516266e-01, -9.62560847e-02, -1.59343615e-01,\n",
       "          3.48100036e-01, -1.25904754e-01, -4.35164534e-02,\n",
       "         -3.09185416e-01, -3.70212317e-01, -7.59672225e-02,\n",
       "          4.31984633e-01],\n",
       "        [-3.17018456e-03,  6.44137800e-01, -3.29990625e-01,\n",
       "         -3.38859349e-01,  5.68899035e-01,  2.53043026e-01,\n",
       "          2.30194271e-01,  1.02516539e-01, -4.08527046e-01,\n",
       "         -7.04031765e-01],\n",
       "        [-3.37742031e-01,  9.67588797e-02, -1.79794043e-01,\n",
       "          2.73333251e-01, -3.32955927e-01,  2.15615723e-02,\n",
       "         -2.83269346e-01, -3.33337635e-01, -1.10846058e-01,\n",
       "         -3.45938295e-01],\n",
       "        [-4.45826985e-02, -4.15382087e-01,  8.69467705e-02,\n",
       "         -1.67710721e-01, -3.54705364e-01,  1.43309027e-01,\n",
       "          2.69045413e-01,  3.45811546e-01,  3.17790985e-01,\n",
       "          1.51531622e-01],\n",
       "        [ 2.03828990e-01, -2.75417298e-01, -3.38218398e-02,\n",
       "         -1.49800152e-01, -7.24542961e-02,  3.61191273e-01,\n",
       "          7.84174353e-03, -2.16635600e-01, -3.79352808e-01,\n",
       "          2.81094462e-01],\n",
       "        [-1.56479399e-03, -4.42146897e-01,  5.21478355e-01,\n",
       "         -4.09246773e-01,  2.74094403e-01, -2.51080126e-01,\n",
       "          2.78179199e-01,  1.21002682e-01, -1.61168009e-01,\n",
       "         -5.98928750e-01],\n",
       "        [ 6.49437085e-02,  9.03769061e-02, -2.11768612e-01,\n",
       "          1.29557222e-01, -1.07732955e-02,  3.16589385e-01,\n",
       "          6.17802795e-03, -3.48721415e-01,  1.68631777e-01,\n",
       "         -2.78621584e-01],\n",
       "        [-2.31918499e-01,  1.99966747e-02,  3.45343977e-01,\n",
       "          3.66104484e-01, -1.73348621e-01,  4.22983468e-02,\n",
       "         -1.97019383e-01,  2.01910302e-01,  1.01383319e-02,\n",
       "         -3.57325882e-01],\n",
       "        [-4.00657624e-01,  3.91530335e-01,  6.21846020e-02,\n",
       "          3.89420360e-01,  3.76381487e-01,  2.55831271e-01,\n",
       "          2.23686174e-01,  2.42455184e-01,  2.28150144e-01,\n",
       "         -4.01010275e-01],\n",
       "        [-3.03009033e-01, -4.98542428e-01, -2.45064311e-02,\n",
       "         -2.35143870e-01,  2.57429957e-01, -2.54920512e-01,\n",
       "          2.80610085e-01,  3.09834540e-01, -7.05896541e-02,\n",
       "          2.37567991e-01],\n",
       "        [-4.76067424e-01, -2.86456615e-01, -4.11856361e-02,\n",
       "          2.79114217e-01,  3.78461450e-01,  5.02296805e-01,\n",
       "         -5.27147889e-01,  4.04868454e-01, -5.70086017e-02,\n",
       "         -2.39601731e-01],\n",
       "        [ 2.01127809e-02, -1.52301624e-01,  5.22508658e-02,\n",
       "         -1.00637518e-01, -1.18582912e-01, -3.47098529e-01,\n",
       "         -2.46620297e-01,  6.24301508e-02,  3.83241385e-01,\n",
       "          2.68657804e-01],\n",
       "        [-1.51140541e-01,  2.52623528e-01,  4.72929537e-01,\n",
       "          9.84304696e-02, -7.57360011e-02, -3.71847928e-01,\n",
       "         -3.40061218e-01,  4.51514244e-01, -4.75326806e-01,\n",
       "         -5.23780882e-01],\n",
       "        [-3.57148826e-01, -2.33925924e-01,  4.03262407e-01,\n",
       "         -6.56046867e-02,  7.46326149e-02, -7.95705989e-02,\n",
       "          3.28174412e-01, -6.13738835e-01,  1.45329475e-01,\n",
       "          2.70507365e-01],\n",
       "        [-1.06958048e-02,  1.41790286e-01, -8.07811469e-02,\n",
       "          2.37696748e-02,  3.10676098e-01, -2.49038428e-01,\n",
       "         -2.48506606e-01, -2.59281993e-02,  3.74992639e-01,\n",
       "         -2.27617323e-01],\n",
       "        [-3.93061578e-01,  2.95888364e-01, -1.16251037e-01,\n",
       "          2.75144368e-01, -3.89202446e-01,  4.50907409e-01,\n",
       "         -2.71580487e-01,  1.18411727e-01, -1.25301197e-01,\n",
       "          1.46302998e-01],\n",
       "        [-1.98323876e-02,  9.05673429e-02,  2.99698580e-02,\n",
       "          2.97917034e-02, -4.93039221e-01, -1.50479704e-01,\n",
       "         -2.78299451e-01,  1.32951155e-01,  1.02781318e-01,\n",
       "         -3.43764991e-01],\n",
       "        [ 1.82323530e-01, -9.79615748e-02,  1.52572721e-01,\n",
       "          1.28593937e-01, -3.54291916e-01, -1.84921116e-01,\n",
       "         -4.09006417e-01,  1.15925513e-01, -2.85652608e-01,\n",
       "          7.49829262e-02],\n",
       "        [-5.10556041e-04,  3.99349891e-02, -4.97814029e-01,\n",
       "          3.74561958e-02,  3.42344195e-01, -3.79041612e-01,\n",
       "          2.34946519e-01, -6.34966493e-02,  2.28277132e-01,\n",
       "          1.15312800e-01],\n",
       "        [ 2.29081407e-01, -3.77110243e-01,  9.49671119e-02,\n",
       "          3.49100322e-01,  2.60815889e-01, -3.85622829e-02,\n",
       "         -2.12433740e-01, -2.32121393e-01,  3.77758103e-03,\n",
       "         -2.17938080e-01],\n",
       "        [ 4.89219800e-02, -1.51989877e-01,  4.72333133e-01,\n",
       "         -3.24818432e-01,  1.90289214e-01,  2.54065365e-01,\n",
       "          1.11090779e-01, -3.32242548e-01,  3.20684671e-01,\n",
       "         -5.67316949e-01],\n",
       "        [-1.05411120e-01,  2.93170065e-01,  2.50095040e-01,\n",
       "         -2.88334578e-01,  1.11773707e-01, -1.99113488e-01,\n",
       "          3.32595110e-01, -2.53500581e-01,  9.91835445e-02,\n",
       "          1.84151173e-01],\n",
       "        [ 3.38400245e-01, -4.23072845e-01, -2.22313568e-01,\n",
       "         -2.00001150e-02, -9.15861223e-03, -1.31229103e-01,\n",
       "          8.89282383e-04,  5.42177521e-02,  3.17107856e-01,\n",
       "          2.67627954e-01],\n",
       "        [-2.73690403e-01, -1.60902590e-01,  3.73680115e-01,\n",
       "         -1.30369574e-01,  2.67297506e-01, -1.46918431e-01,\n",
       "         -1.74559325e-01, -5.10306120e-01, -3.23404133e-01,\n",
       "          1.60691768e-01],\n",
       "        [ 2.40175650e-01,  3.26757953e-02, -5.42791367e-01,\n",
       "          3.53669375e-01,  2.43469894e-01, -2.90832907e-01,\n",
       "          2.67547280e-01, -2.25498877e-03, -5.96776307e-01,\n",
       "         -1.29638640e-02],\n",
       "        [-3.21480840e-01,  3.02501380e-01,  1.19915396e-01,\n",
       "         -5.50925016e-01, -1.63202971e-01,  3.89874801e-02,\n",
       "          3.78953934e-01,  7.32192174e-02,  4.25233662e-01,\n",
       "          4.36695784e-01],\n",
       "        [-2.37053439e-01,  1.18498974e-01,  2.94523329e-01,\n",
       "         -2.20636711e-01,  3.98885071e-01, -4.26504880e-01,\n",
       "         -2.37727851e-01, -3.67992669e-01,  1.65234372e-01,\n",
       "         -2.25375503e-01],\n",
       "        [ 5.92879131e-02, -3.43094707e-01, -7.05549270e-02,\n",
       "          1.07465729e-01, -3.45314354e-01,  2.51259893e-01,\n",
       "          1.00279070e-01, -3.23472470e-01,  1.14068747e-01,\n",
       "          2.81125847e-02],\n",
       "        [ 2.27062702e-01, -1.85638070e-01,  2.84716308e-01,\n",
       "         -2.44559735e-01,  2.17170656e-01,  3.02870303e-01,\n",
       "          3.17884445e-01, -3.82624894e-01,  2.88320512e-01,\n",
       "         -2.67998695e-01],\n",
       "        [ 1.93267226e-01, -7.66182989e-02, -1.96476072e-01,\n",
       "         -2.99555779e-01,  1.91588372e-01, -3.60132664e-01,\n",
       "          2.32229218e-01, -4.27172601e-01, -1.15354098e-01,\n",
       "          1.19236521e-01],\n",
       "        [ 3.01368356e-01, -1.07779764e-01,  2.47329950e-01,\n",
       "         -1.56707168e-01,  7.42278248e-02, -8.04355815e-02,\n",
       "         -1.56058464e-02,  3.30803692e-01, -1.69016510e-01,\n",
       "         -1.25567168e-01],\n",
       "        [ 1.50815964e-01, -4.25956637e-01, -1.23981826e-01,\n",
       "          3.08686256e-01, -2.44154170e-01,  3.20743740e-01,\n",
       "         -2.61495411e-01, -8.16578865e-02,  1.16406307e-01,\n",
       "          2.25146022e-03],\n",
       "        [-4.15556610e-01, -2.34645337e-01, -1.75019816e-01,\n",
       "          2.27042019e-01,  3.76955062e-01,  2.99870253e-01,\n",
       "         -2.71735311e-01, -4.03605580e-01, -9.71715674e-02,\n",
       "          1.09709308e-01],\n",
       "        [ 2.88964808e-01,  1.54643178e-01, -1.60439268e-01,\n",
       "         -2.57845391e-02, -1.64138898e-01,  3.41192573e-01,\n",
       "         -7.47580035e-03, -2.87610561e-01,  3.74580801e-01,\n",
       "         -2.89159477e-01],\n",
       "        [ 3.19738150e-01, -1.78086728e-01, -6.77011311e-01,\n",
       "         -5.31910002e-01,  3.54022235e-01,  6.56543911e-01,\n",
       "          5.38632870e-01, -4.02313098e-02,  1.78396448e-01,\n",
       "          4.31196868e-01],\n",
       "        [-1.21933676e-01, -2.32381642e-01, -3.01753074e-01,\n",
       "         -9.81894806e-02,  8.12126249e-02, -2.22183421e-01,\n",
       "         -2.58256972e-01,  3.59389305e-01,  4.73003946e-02,\n",
       "         -1.87896490e-01],\n",
       "        [-2.49939337e-01,  1.93758115e-01, -1.84998121e-02,\n",
       "          3.75590920e-01, -4.19763088e-01,  3.11759979e-01,\n",
       "          7.88322762e-02, -1.55780435e-01,  1.96087167e-01,\n",
       "         -9.26010460e-02],\n",
       "        [-2.29832023e-01,  2.30303973e-01,  2.40766108e-01,\n",
       "         -4.20085907e-01,  2.53826916e-01, -4.10051078e-01,\n",
       "         -3.00281882e-01,  1.18122995e-01, -8.66435543e-02,\n",
       "          2.26044744e-01],\n",
       "        [ 1.33068174e-01, -1.94535971e-01, -3.73350531e-01,\n",
       "          3.91290665e-01,  6.93719313e-02,  4.46157455e-01,\n",
       "         -1.85822379e-02, -1.65236473e-01, -2.19115298e-02,\n",
       "          3.78894210e-01],\n",
       "        [ 3.71570200e-01,  4.19926383e-02,  2.49293774e-01,\n",
       "          4.92540374e-02, -2.49597669e-01,  4.23359172e-03,\n",
       "         -7.72310123e-02, -2.13001624e-01, -2.08376899e-01,\n",
       "         -1.97336942e-01],\n",
       "        [ 3.44299138e-01,  4.97556813e-02, -1.55044675e-01,\n",
       "         -4.27618027e-01,  9.69497263e-02, -2.56742597e-01,\n",
       "          1.63737193e-01,  4.67685223e-01, -3.54938060e-02,\n",
       "         -1.84476282e-02],\n",
       "        [-3.33008051e-01,  4.35308367e-02, -2.00464010e-01,\n",
       "         -6.51526526e-02,  6.16625287e-02,  1.21383794e-01,\n",
       "         -2.83721328e-01,  3.22285622e-01, -3.19714457e-01,\n",
       "          6.99468851e-02],\n",
       "        [ 2.14263320e-01, -1.91416647e-02,  2.53532201e-01,\n",
       "          1.53551579e-01, -8.82375911e-02,  3.84843200e-02,\n",
       "          1.56375710e-02,  4.06486273e-01, -3.99088383e-01,\n",
       "         -3.41132015e-01]], dtype=float32),\n",
       " array([-0.12543269,  0.06943326,  0.02147546, -0.03645208, -0.00770996,\n",
       "         0.11889728, -0.06301852,  0.08854801, -0.10084939, -0.01300905],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()\n",
    "# displays the weights and biases of second layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Storing and retrieving the weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save_weights('my_model_weights.h5')\n",
    "recovered_model = model.load_weights('my_model_weights.h5')\n",
    "# model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Storing and retrieving the models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save('model.h5')\n",
    "loaded_model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# cloning the models\n",
    "model_cloned = keras.models.clone_model(model)\n",
    "new_weights = model_cloned.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(): \n",
    "    model_hm = keras.Sequential([\n",
    "        # input layer 784 neurons to first hidden layer with 64 neurons\n",
    "        keras.layers.Dense(64, input_shape = (784,), activation='relu'), \n",
    "        # first hidden layer with 64 neurons\n",
    "        #keras.layers.Dense(64, activation='relu'), \n",
    "        # second hidden layer with 64 neurons\n",
    "        #keras.layers.Dense(64, activation='relu'), \n",
    "        # Output layer with 10 neurons\n",
    "        keras.layers.Dense(10, activation='sigmoid')\n",
    "    ])\n",
    "    model_hm.compile(\n",
    "        optimizer = 'SGD',\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    return model_hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback): \n",
    "    iteration = 0\n",
    "    initial_weights = 0\n",
    "    previous_weights = 0\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.initial_weights = model_hm.get_weights() \n",
    "        self.initial_weights = np.array(self.initial_weights,dtype=object)\n",
    "        self.previous_weights = self.initial_weights \n",
    "    \n",
    "    def on_train_batch_end(self, epoch, logs=None): \n",
    "        counter = 0\n",
    "        num_layers = len(model_hm.layers)  \n",
    "        current_weights = model_hm.get_weights()\n",
    "        current_weights = np.array(current_weights,dtype=object)\n",
    "        call = np.vectorize(apply_gm) \n",
    "        \n",
    "        for i in range(num_layers):  \n",
    "            current_weights[counter] = call(self.previous_weights[counter], current_weights[counter])\n",
    "            counter = counter + 2\n",
    "            \n",
    "        updated = current_weights.tolist()   \n",
    "        model_hm.set_weights(updated)\n",
    "        self.previous_weights = current_weights\n",
    "        self.iteration = self.iteration + 1  \n",
    "        \n",
    "    def apply_gm(v1,v2):     \n",
    "        if v1==0 or v2==0:\n",
    "            return v2\n",
    "        elif v1>0 and v2>0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            min1 = min(v1,v2)\n",
    "            diff = abs(hm-min1)\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        elif v1<0 and v2<0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            max1 = max(v1,v2)\n",
    "            diff = abs(hm-max1)\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        else:\n",
    "            return v2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  5/469 [..............................] - ETA: 22s - loss: 2.3138 - accuracy: 0.1031WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0458s). Check your callbacks.\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 1.0128 - accuracy: 0.7540\n",
      "Epoch 2/300\n",
      "469/469 [==============================] - 22s 46ms/step - loss: 0.4794 - accuracy: 0.8745\n",
      "Epoch 3/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.3970 - accuracy: 0.8908\n",
      "Epoch 4/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.3573 - accuracy: 0.9002\n",
      "Epoch 5/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.3314 - accuracy: 0.9062\n",
      "Epoch 6/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.3124 - accuracy: 0.9114\n",
      "Epoch 7/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2969 - accuracy: 0.9160\n",
      "Epoch 8/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2837 - accuracy: 0.9198\n",
      "Epoch 9/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.2724 - accuracy: 0.9231\n",
      "Epoch 10/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2621 - accuracy: 0.9266\n",
      "Epoch 11/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2532 - accuracy: 0.9288\n",
      "Epoch 12/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2451 - accuracy: 0.9315\n",
      "Epoch 13/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.2377 - accuracy: 0.9336\n",
      "Epoch 14/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.2309 - accuracy: 0.9356\n",
      "Epoch 15/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.2246 - accuracy: 0.9375\n",
      "Epoch 16/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.2188 - accuracy: 0.9394\n",
      "Epoch 17/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2134 - accuracy: 0.9407\n",
      "Epoch 18/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2083 - accuracy: 0.9421\n",
      "Epoch 19/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.2034 - accuracy: 0.9434\n",
      "Epoch 20/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.1988 - accuracy: 0.9449\n",
      "Epoch 21/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.1945 - accuracy: 0.9462\n",
      "Epoch 22/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.1904 - accuracy: 0.9468\n",
      "Epoch 23/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.1864 - accuracy: 0.9481\n",
      "Epoch 24/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.1827 - accuracy: 0.9488\n",
      "Epoch 25/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.1791 - accuracy: 0.9499\n",
      "Epoch 26/300\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1756 - accuracy: 0.9511\n",
      "Epoch 27/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.1723 - accuracy: 0.9521\n",
      "Epoch 28/300\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.1692 - accuracy: 0.9528\n",
      "Epoch 29/300\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 0.1662 - accuracy: 0.9537\n",
      "Epoch 30/300\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 0.1634 - accuracy: 0.9540\n",
      "Epoch 31/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.1606 - accuracy: 0.9550\n",
      "Epoch 32/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.1579 - accuracy: 0.9559\n",
      "Epoch 33/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.1554 - accuracy: 0.9562\n",
      "Epoch 34/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.1528 - accuracy: 0.9575\n",
      "Epoch 35/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.1505 - accuracy: 0.9581\n",
      "Epoch 36/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.1481 - accuracy: 0.9589\n",
      "Epoch 37/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.1459 - accuracy: 0.9597\n",
      "Epoch 38/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.1438 - accuracy: 0.9597\n",
      "Epoch 39/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.1418 - accuracy: 0.9608\n",
      "Epoch 40/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.1397 - accuracy: 0.9614\n",
      "Epoch 41/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.1378 - accuracy: 0.9621\n",
      "Epoch 42/300\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1359 - accuracy: 0.9623\n",
      "Epoch 43/300\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.1340 - accuracy: 0.9628\n",
      "Epoch 44/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.1323 - accuracy: 0.9634\n",
      "Epoch 45/300\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.1306 - accuracy: 0.9638\n",
      "Epoch 46/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.1288 - accuracy: 0.9643\n",
      "Epoch 47/300\n",
      "469/469 [==============================] - 28s 61ms/step - loss: 0.1272 - accuracy: 0.9645\n",
      "Epoch 48/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.1256 - accuracy: 0.9647\n",
      "Epoch 49/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.1240 - accuracy: 0.9654\n",
      "Epoch 50/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.1226 - accuracy: 0.9658\n",
      "Epoch 51/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.1212 - accuracy: 0.9665\n",
      "Epoch 52/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.1197 - accuracy: 0.9667\n",
      "Epoch 53/300\n",
      "469/469 [==============================] - 29s 61ms/step - loss: 0.1182 - accuracy: 0.9672\n",
      "Epoch 54/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.1170 - accuracy: 0.9675\n",
      "Epoch 55/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.1156 - accuracy: 0.9677\n",
      "Epoch 56/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.1144 - accuracy: 0.9681\n",
      "Epoch 57/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.1131 - accuracy: 0.9689\n",
      "Epoch 58/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.1118 - accuracy: 0.9688\n",
      "Epoch 59/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.1106 - accuracy: 0.9696\n",
      "Epoch 60/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.1094 - accuracy: 0.9696\n",
      "Epoch 61/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.1083 - accuracy: 0.9698\n",
      "Epoch 62/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.1071 - accuracy: 0.9702\n",
      "Epoch 63/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.1060 - accuracy: 0.9707\n",
      "Epoch 64/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.1050 - accuracy: 0.9711\n",
      "Epoch 65/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.1038 - accuracy: 0.9713\n",
      "Epoch 66/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.1029 - accuracy: 0.9714\n",
      "Epoch 67/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.1017 - accuracy: 0.9719\n",
      "Epoch 68/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.1008 - accuracy: 0.9722\n",
      "Epoch 69/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0998 - accuracy: 0.9726\n",
      "Epoch 70/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0989 - accuracy: 0.9726\n",
      "Epoch 71/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0979 - accuracy: 0.9731\n",
      "Epoch 72/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0970 - accuracy: 0.9730\n",
      "Epoch 73/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0961 - accuracy: 0.9736\n",
      "Epoch 74/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0951 - accuracy: 0.9737\n",
      "Epoch 75/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0943 - accuracy: 0.9737\n",
      "Epoch 76/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0934 - accuracy: 0.9741\n",
      "Epoch 77/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0926 - accuracy: 0.9745\n",
      "Epoch 78/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0918 - accuracy: 0.9747\n",
      "Epoch 79/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0908 - accuracy: 0.9753\n",
      "Epoch 80/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0901 - accuracy: 0.9752\n",
      "Epoch 81/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0893 - accuracy: 0.9755\n",
      "Epoch 82/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0886 - accuracy: 0.9756\n",
      "Epoch 83/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0878 - accuracy: 0.9758\n",
      "Epoch 84/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0870 - accuracy: 0.9759\n",
      "Epoch 85/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0864 - accuracy: 0.9760\n",
      "Epoch 86/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0855 - accuracy: 0.9765\n",
      "Epoch 87/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0849 - accuracy: 0.9770\n",
      "Epoch 88/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0841 - accuracy: 0.9773\n",
      "Epoch 89/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0835 - accuracy: 0.9773\n",
      "Epoch 90/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0827 - accuracy: 0.9772\n",
      "Epoch 91/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0822 - accuracy: 0.9773\n",
      "Epoch 92/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0814 - accuracy: 0.9779\n",
      "Epoch 93/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0808 - accuracy: 0.9779\n",
      "Epoch 94/300\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 0.0801 - accuracy: 0.9780\n",
      "Epoch 95/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0795 - accuracy: 0.9784\n",
      "Epoch 96/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0788 - accuracy: 0.9784\n",
      "Epoch 97/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0782 - accuracy: 0.9785\n",
      "Epoch 98/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0777 - accuracy: 0.9789\n",
      "Epoch 99/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0771 - accuracy: 0.9789\n",
      "Epoch 100/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0765 - accuracy: 0.9790\n",
      "Epoch 101/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0758 - accuracy: 0.9793\n",
      "Epoch 102/300\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0753 - accuracy: 0.9795\n",
      "Epoch 103/300\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0747 - accuracy: 0.9797\n",
      "Epoch 104/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0742 - accuracy: 0.9795\n",
      "Epoch 105/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0736 - accuracy: 0.9799\n",
      "Epoch 106/300\n",
      "469/469 [==============================] - 29s 61ms/step - loss: 0.0731 - accuracy: 0.9801\n",
      "Epoch 107/300\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 0.0726 - accuracy: 0.9801\n",
      "Epoch 108/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0720 - accuracy: 0.9802\n",
      "Epoch 109/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0715 - accuracy: 0.9803\n",
      "Epoch 110/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0709 - accuracy: 0.9807\n",
      "Epoch 111/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0705 - accuracy: 0.9807\n",
      "Epoch 112/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0700 - accuracy: 0.9808\n",
      "Epoch 113/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0694 - accuracy: 0.9812\n",
      "Epoch 114/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0690 - accuracy: 0.9813\n",
      "Epoch 115/300\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 0.0685 - accuracy: 0.9817\n",
      "Epoch 116/300\n",
      "469/469 [==============================] - 32s 67ms/step - loss: 0.0680 - accuracy: 0.9818\n",
      "Epoch 117/300\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0675 - accuracy: 0.9818\n",
      "Epoch 118/300\n",
      "469/469 [==============================] - 34s 73ms/step - loss: 0.0670 - accuracy: 0.9819\n",
      "Epoch 119/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0666 - accuracy: 0.9821\n",
      "Epoch 120/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0661 - accuracy: 0.9821\n",
      "Epoch 121/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0657 - accuracy: 0.9822\n",
      "Epoch 122/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0652 - accuracy: 0.9824\n",
      "Epoch 123/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0649 - accuracy: 0.9826\n",
      "Epoch 124/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0644 - accuracy: 0.9827\n",
      "Epoch 125/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0639 - accuracy: 0.9828\n",
      "Epoch 126/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0635 - accuracy: 0.9832\n",
      "Epoch 127/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0632 - accuracy: 0.9832\n",
      "Epoch 128/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0627 - accuracy: 0.9830\n",
      "Epoch 129/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0623 - accuracy: 0.9833\n",
      "Epoch 130/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0619 - accuracy: 0.9833\n",
      "Epoch 131/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0615 - accuracy: 0.9833\n",
      "Epoch 132/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0611 - accuracy: 0.9835\n",
      "Epoch 133/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0606 - accuracy: 0.9837\n",
      "Epoch 134/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0603 - accuracy: 0.9839\n",
      "Epoch 135/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0599 - accuracy: 0.9841\n",
      "Epoch 136/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0596 - accuracy: 0.9841\n",
      "Epoch 137/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0591 - accuracy: 0.9842\n",
      "Epoch 138/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0588 - accuracy: 0.9843\n",
      "Epoch 139/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0584 - accuracy: 0.9845\n",
      "Epoch 140/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0581 - accuracy: 0.9844\n",
      "Epoch 141/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0577 - accuracy: 0.9845\n",
      "Epoch 142/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0573 - accuracy: 0.9847\n",
      "Epoch 143/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0570 - accuracy: 0.9848\n",
      "Epoch 144/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0566 - accuracy: 0.9851\n",
      "Epoch 145/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0563 - accuracy: 0.9851\n",
      "Epoch 146/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0559 - accuracy: 0.9852\n",
      "Epoch 147/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0556 - accuracy: 0.9854\n",
      "Epoch 148/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0553 - accuracy: 0.9854\n",
      "Epoch 149/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0549 - accuracy: 0.9855\n",
      "Epoch 150/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0546 - accuracy: 0.9856\n",
      "Epoch 151/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0542 - accuracy: 0.9858\n",
      "Epoch 152/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0539 - accuracy: 0.9856\n",
      "Epoch 153/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0535 - accuracy: 0.9861\n",
      "Epoch 154/300\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0533 - accuracy: 0.9860\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0530 - accuracy: 0.9861\n",
      "Epoch 156/300\n",
      "469/469 [==============================] - 25s 52ms/step - loss: 0.0527 - accuracy: 0.9862\n",
      "Epoch 157/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0523 - accuracy: 0.9864\n",
      "Epoch 158/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0520 - accuracy: 0.9863\n",
      "Epoch 159/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0516 - accuracy: 0.9868\n",
      "Epoch 160/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0514 - accuracy: 0.9867\n",
      "Epoch 161/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0512 - accuracy: 0.9869\n",
      "Epoch 162/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0509 - accuracy: 0.9868\n",
      "Epoch 163/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0505 - accuracy: 0.9869\n",
      "Epoch 164/300\n",
      "469/469 [==============================] - 26s 57ms/step - loss: 0.0502 - accuracy: 0.9869\n",
      "Epoch 165/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0500 - accuracy: 0.9870\n",
      "Epoch 166/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0496 - accuracy: 0.9870\n",
      "Epoch 167/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0494 - accuracy: 0.9872\n",
      "Epoch 168/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0491 - accuracy: 0.9875\n",
      "Epoch 169/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0489 - accuracy: 0.9872\n",
      "Epoch 170/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0486 - accuracy: 0.9876\n",
      "Epoch 171/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0483 - accuracy: 0.9876\n",
      "Epoch 172/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0480 - accuracy: 0.9878\n",
      "Epoch 173/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0478 - accuracy: 0.9879\n",
      "Epoch 174/300\n",
      "469/469 [==============================] - 26s 54ms/step - loss: 0.0475 - accuracy: 0.9879\n",
      "Epoch 175/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0472 - accuracy: 0.9878\n",
      "Epoch 176/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0469 - accuracy: 0.9881\n",
      "Epoch 177/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0467 - accuracy: 0.9883\n",
      "Epoch 178/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0464 - accuracy: 0.9882\n",
      "Epoch 179/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0462 - accuracy: 0.9881\n",
      "Epoch 180/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0459 - accuracy: 0.9883\n",
      "Epoch 181/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0457 - accuracy: 0.9885\n",
      "Epoch 182/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0454 - accuracy: 0.9886\n",
      "Epoch 183/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0451 - accuracy: 0.9885\n",
      "Epoch 184/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0449 - accuracy: 0.9887\n",
      "Epoch 185/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0447 - accuracy: 0.9888\n",
      "Epoch 186/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0444 - accuracy: 0.9886\n",
      "Epoch 187/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0441 - accuracy: 0.9890\n",
      "Epoch 188/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0440 - accuracy: 0.9889\n",
      "Epoch 189/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0437 - accuracy: 0.9892\n",
      "Epoch 190/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0435 - accuracy: 0.9891\n",
      "Epoch 191/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0432 - accuracy: 0.9891\n",
      "Epoch 192/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0430 - accuracy: 0.9892\n",
      "Epoch 193/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0427 - accuracy: 0.9893\n",
      "Epoch 194/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0426 - accuracy: 0.9893\n",
      "Epoch 195/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0423 - accuracy: 0.9893\n",
      "Epoch 196/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0421 - accuracy: 0.9894\n",
      "Epoch 197/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0419 - accuracy: 0.9896\n",
      "Epoch 198/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0417 - accuracy: 0.9898\n",
      "Epoch 199/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0415 - accuracy: 0.9897\n",
      "Epoch 200/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0412 - accuracy: 0.9898\n",
      "Epoch 201/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0410 - accuracy: 0.9900\n",
      "Epoch 202/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0408 - accuracy: 0.9901\n",
      "Epoch 203/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0406 - accuracy: 0.9901\n",
      "Epoch 204/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0404 - accuracy: 0.9902\n",
      "Epoch 205/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0402 - accuracy: 0.9901\n",
      "Epoch 206/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0400 - accuracy: 0.9903\n",
      "Epoch 207/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0398 - accuracy: 0.9904\n",
      "Epoch 208/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0397 - accuracy: 0.9902\n",
      "Epoch 209/300\n",
      "469/469 [==============================] - 22s 47ms/step - loss: 0.0393 - accuracy: 0.9904\n",
      "Epoch 210/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0392 - accuracy: 0.9905\n",
      "Epoch 211/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0390 - accuracy: 0.9907\n",
      "Epoch 212/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0388 - accuracy: 0.9907\n",
      "Epoch 213/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0386 - accuracy: 0.9907\n",
      "Epoch 214/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0384 - accuracy: 0.9906\n",
      "Epoch 215/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0382 - accuracy: 0.9909\n",
      "Epoch 216/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0380 - accuracy: 0.9906\n",
      "Epoch 217/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0378 - accuracy: 0.9908\n",
      "Epoch 218/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0376 - accuracy: 0.9909\n",
      "Epoch 219/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0374 - accuracy: 0.9910\n",
      "Epoch 220/300\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0373 - accuracy: 0.9911\n",
      "Epoch 221/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0371 - accuracy: 0.9911\n",
      "Epoch 222/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0369 - accuracy: 0.9912\n",
      "Epoch 223/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0366 - accuracy: 0.9915\n",
      "Epoch 224/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0365 - accuracy: 0.9916\n",
      "Epoch 225/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0364 - accuracy: 0.9914\n",
      "Epoch 226/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0362 - accuracy: 0.9915\n",
      "Epoch 227/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0359 - accuracy: 0.9916\n",
      "Epoch 228/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0358 - accuracy: 0.9915\n",
      "Epoch 229/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0356 - accuracy: 0.9917\n",
      "Epoch 230/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0355 - accuracy: 0.9917\n",
      "Epoch 231/300\n",
      "469/469 [==============================] - 25s 52ms/step - loss: 0.0353 - accuracy: 0.9920\n",
      "Epoch 232/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0351 - accuracy: 0.9917\n",
      "Epoch 233/300\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0349 - accuracy: 0.9920\n",
      "Epoch 234/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0347 - accuracy: 0.9921\n",
      "Epoch 235/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0346 - accuracy: 0.9920\n",
      "Epoch 236/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0344 - accuracy: 0.9923\n",
      "Epoch 237/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0342 - accuracy: 0.9920\n",
      "Epoch 238/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0340 - accuracy: 0.9921\n",
      "Epoch 239/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0339 - accuracy: 0.9923\n",
      "Epoch 240/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0337 - accuracy: 0.9922\n",
      "Epoch 241/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0336 - accuracy: 0.9923\n",
      "Epoch 242/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0335 - accuracy: 0.9923\n",
      "Epoch 243/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0333 - accuracy: 0.9924\n",
      "Epoch 244/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0331 - accuracy: 0.9925\n",
      "Epoch 245/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0330 - accuracy: 0.9926\n",
      "Epoch 246/300\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0328 - accuracy: 0.9927\n",
      "Epoch 247/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0326 - accuracy: 0.9926\n",
      "Epoch 248/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0325 - accuracy: 0.9929\n",
      "Epoch 249/300\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0323 - accuracy: 0.9928\n",
      "Epoch 250/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0322 - accuracy: 0.9929\n",
      "Epoch 251/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0320 - accuracy: 0.9928\n",
      "Epoch 252/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0318 - accuracy: 0.9929\n",
      "Epoch 253/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0317 - accuracy: 0.9928\n",
      "Epoch 254/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0316 - accuracy: 0.9931\n",
      "Epoch 255/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0314 - accuracy: 0.9931\n",
      "Epoch 256/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0313 - accuracy: 0.9929\n",
      "Epoch 257/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0312 - accuracy: 0.9930\n",
      "Epoch 258/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0309 - accuracy: 0.9931\n",
      "Epoch 259/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0308 - accuracy: 0.9931\n",
      "Epoch 260/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0307 - accuracy: 0.9931\n",
      "Epoch 261/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0305 - accuracy: 0.9934\n",
      "Epoch 262/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0304 - accuracy: 0.9933\n",
      "Epoch 263/300\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0303 - accuracy: 0.9935\n",
      "Epoch 264/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0301 - accuracy: 0.9936\n",
      "Epoch 265/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0300 - accuracy: 0.9934\n",
      "Epoch 266/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0298 - accuracy: 0.9935\n",
      "Epoch 267/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0297 - accuracy: 0.9935\n",
      "Epoch 268/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0295 - accuracy: 0.9934\n",
      "Epoch 269/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0294 - accuracy: 0.9936\n",
      "Epoch 270/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0293 - accuracy: 0.9937\n",
      "Epoch 271/300\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0291 - accuracy: 0.9938\n",
      "Epoch 272/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0290 - accuracy: 0.9937\n",
      "Epoch 273/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0289 - accuracy: 0.9939\n",
      "Epoch 274/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0287 - accuracy: 0.9937\n",
      "Epoch 275/300\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0286 - accuracy: 0.9939\n",
      "Epoch 276/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0285 - accuracy: 0.9938\n",
      "Epoch 277/300\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0283 - accuracy: 0.9939\n",
      "Epoch 278/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0281 - accuracy: 0.9940\n",
      "Epoch 279/300\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0280 - accuracy: 0.9941\n",
      "Epoch 280/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0280 - accuracy: 0.9942\n",
      "Epoch 281/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0278 - accuracy: 0.9941\n",
      "Epoch 282/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0277 - accuracy: 0.9941\n",
      "Epoch 283/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0276 - accuracy: 0.9941\n",
      "Epoch 284/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0274 - accuracy: 0.9942\n",
      "Epoch 285/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0273 - accuracy: 0.9944\n",
      "Epoch 286/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0272 - accuracy: 0.9943\n",
      "Epoch 287/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0271 - accuracy: 0.9944\n",
      "Epoch 288/300\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0269 - accuracy: 0.9942\n",
      "Epoch 289/300\n",
      "469/469 [==============================] - 25s 52ms/step - loss: 0.0268 - accuracy: 0.9945\n",
      "Epoch 290/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0267 - accuracy: 0.9945\n",
      "Epoch 291/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0266 - accuracy: 0.9944\n",
      "Epoch 292/300\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0265 - accuracy: 0.9944\n",
      "Epoch 293/300\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0264 - accuracy: 0.9945\n",
      "Epoch 294/300\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0262 - accuracy: 0.9947\n",
      "Epoch 295/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0261 - accuracy: 0.9947\n",
      "Epoch 296/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0260 - accuracy: 0.9947\n",
      "Epoch 297/300\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0259 - accuracy: 0.9948\n",
      "Epoch 298/300\n",
      "469/469 [==============================] - 27s 57ms/step - loss: 0.0258 - accuracy: 0.9947\n",
      "Epoch 299/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0257 - accuracy: 0.9946\n",
      "Epoch 300/300\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 0.0255 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c092e201c0>"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hm = get_model()\n",
    "model_hm.fit(X_train_normalized, y_train, epochs = 300, verbose=1, callbacks=[CustomCallback()], batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.2273 - accuracy: 0.6990\n",
      "Epoch 2/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5731 - accuracy: 0.8595\n",
      "Epoch 3/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.8797\n",
      "Epoch 4/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4020 - accuracy: 0.8899\n",
      "Epoch 5/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3710 - accuracy: 0.8965\n",
      "Epoch 6/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.9015\n",
      "Epoch 7/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3327 - accuracy: 0.9061\n",
      "Epoch 8/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.9093\n",
      "Epoch 9/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.9128\n",
      "Epoch 10/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2979 - accuracy: 0.9155\n",
      "Epoch 11/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.9179\n",
      "Epoch 12/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.9202\n",
      "Epoch 13/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9220\n",
      "Epoch 14/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.9240\n",
      "Epoch 15/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.9262\n",
      "Epoch 16/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.9275\n",
      "Epoch 17/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2507 - accuracy: 0.9287\n",
      "Epoch 18/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.9308\n",
      "Epoch 19/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.9316\n",
      "Epoch 20/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.9335\n",
      "Epoch 21/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2317 - accuracy: 0.9353\n",
      "Epoch 22/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2275 - accuracy: 0.9359\n",
      "Epoch 23/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2234 - accuracy: 0.9371\n",
      "Epoch 24/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9385\n",
      "Epoch 25/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2157 - accuracy: 0.9396\n",
      "Epoch 26/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2120 - accuracy: 0.9403\n",
      "Epoch 27/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9416\n",
      "Epoch 28/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2051 - accuracy: 0.9423\n",
      "Epoch 29/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9433\n",
      "Epoch 30/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1986 - accuracy: 0.9438\n",
      "Epoch 31/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9450\n",
      "Epoch 32/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.9457\n",
      "Epoch 33/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1896 - accuracy: 0.9465\n",
      "Epoch 34/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.9471\n",
      "Epoch 35/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1841 - accuracy: 0.9479\n",
      "Epoch 36/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.9485\n",
      "Epoch 37/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.9497\n",
      "Epoch 38/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1765 - accuracy: 0.9499\n",
      "Epoch 39/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.9505\n",
      "Epoch 40/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1718 - accuracy: 0.9516\n",
      "Epoch 41/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1696 - accuracy: 0.9520\n",
      "Epoch 42/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9528\n",
      "Epoch 43/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1652 - accuracy: 0.9534\n",
      "Epoch 44/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1632 - accuracy: 0.9538\n",
      "Epoch 45/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9547\n",
      "Epoch 46/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1591 - accuracy: 0.9552\n",
      "Epoch 47/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1573 - accuracy: 0.9556\n",
      "Epoch 48/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1554 - accuracy: 0.9562\n",
      "Epoch 49/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1535 - accuracy: 0.9567\n",
      "Epoch 50/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1518 - accuracy: 0.9569\n",
      "Epoch 51/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9577\n",
      "Epoch 52/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1483 - accuracy: 0.9584\n",
      "Epoch 53/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1467 - accuracy: 0.9585\n",
      "Epoch 54/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1451 - accuracy: 0.9587\n",
      "Epoch 55/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1436 - accuracy: 0.9592\n",
      "Epoch 56/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1420 - accuracy: 0.9600\n",
      "Epoch 57/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9606\n",
      "Epoch 58/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1391 - accuracy: 0.9607\n",
      "Epoch 59/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1377 - accuracy: 0.9612\n",
      "Epoch 60/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1363 - accuracy: 0.9615\n",
      "Epoch 61/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1348 - accuracy: 0.9618\n",
      "Epoch 62/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.1335 - accuracy: 0.9625\n",
      "Epoch 63/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9629\n",
      "Epoch 64/300\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1309 - accuracy: 0.9631\n",
      "Epoch 65/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1297 - accuracy: 0.9635\n",
      "Epoch 66/300\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9636\n",
      "Epoch 67/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1272 - accuracy: 0.9642\n",
      "Epoch 68/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1261 - accuracy: 0.9642\n",
      "Epoch 69/300\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1250 - accuracy: 0.9649\n",
      "Epoch 70/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.9650\n",
      "Epoch 71/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1227 - accuracy: 0.9656\n",
      "Epoch 72/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1217 - accuracy: 0.9655\n",
      "Epoch 73/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.9657\n",
      "Epoch 74/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9660\n",
      "Epoch 75/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1184 - accuracy: 0.9664\n",
      "Epoch 76/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1174 - accuracy: 0.9666\n",
      "Epoch 77/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1164 - accuracy: 0.9669\n",
      "Epoch 78/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1155 - accuracy: 0.9670\n",
      "Epoch 79/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1145 - accuracy: 0.9673\n",
      "Epoch 80/300\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1136 - accuracy: 0.9674\n",
      "Epoch 81/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1127 - accuracy: 0.9680\n",
      "Epoch 82/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1118 - accuracy: 0.9681\n",
      "Epoch 83/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1109 - accuracy: 0.9683\n",
      "Epoch 84/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1101 - accuracy: 0.9685\n",
      "Epoch 85/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1092 - accuracy: 0.9689\n",
      "Epoch 86/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1084 - accuracy: 0.9692\n",
      "Epoch 87/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1075 - accuracy: 0.9694\n",
      "Epoch 88/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1068 - accuracy: 0.9695\n",
      "Epoch 89/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1060 - accuracy: 0.9697\n",
      "Epoch 90/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.9697\n",
      "Epoch 91/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1044 - accuracy: 0.9700\n",
      "Epoch 92/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1037 - accuracy: 0.9705\n",
      "Epoch 93/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9707\n",
      "Epoch 94/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9708\n",
      "Epoch 95/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9709\n",
      "Epoch 96/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9712\n",
      "Epoch 97/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9714\n",
      "Epoch 98/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0994 - accuracy: 0.9717\n",
      "Epoch 99/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9717\n",
      "Epoch 100/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9720\n",
      "Epoch 101/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9720\n",
      "Epoch 102/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9723\n",
      "Epoch 103/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9727\n",
      "Epoch 104/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9726\n",
      "Epoch 105/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9730\n",
      "Epoch 106/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9731\n",
      "Epoch 107/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9736\n",
      "Epoch 108/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9738\n",
      "Epoch 109/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9739\n",
      "Epoch 110/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9743\n",
      "Epoch 111/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9740\n",
      "Epoch 112/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9743\n",
      "Epoch 113/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9745\n",
      "Epoch 114/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9747\n",
      "Epoch 115/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9748\n",
      "Epoch 116/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9750\n",
      "Epoch 117/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9750\n",
      "Epoch 118/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9754\n",
      "Epoch 119/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.9756\n",
      "Epoch 120/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.9755\n",
      "Epoch 121/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.9757\n",
      "Epoch 122/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9762\n",
      "Epoch 123/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.9760\n",
      "Epoch 124/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0845 - accuracy: 0.9764\n",
      "Epoch 125/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0840 - accuracy: 0.9764\n",
      "Epoch 126/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0835 - accuracy: 0.9766\n",
      "Epoch 127/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0830 - accuracy: 0.9766\n",
      "Epoch 128/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9769\n",
      "Epoch 129/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9772\n",
      "Epoch 130/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0816 - accuracy: 0.9771\n",
      "Epoch 131/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9772\n",
      "Epoch 132/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9771\n",
      "Epoch 133/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9774\n",
      "Epoch 134/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9777\n",
      "Epoch 135/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0794 - accuracy: 0.9778\n",
      "Epoch 136/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9780\n",
      "Epoch 137/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0785 - accuracy: 0.9780\n",
      "Epoch 138/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.9781\n",
      "Epoch 139/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0777 - accuracy: 0.9781\n",
      "Epoch 140/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.9782\n",
      "Epoch 141/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9785\n",
      "Epoch 142/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9787\n",
      "Epoch 143/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0760 - accuracy: 0.9787\n",
      "Epoch 144/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9790\n",
      "Epoch 145/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0753 - accuracy: 0.9788\n",
      "Epoch 146/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0749 - accuracy: 0.9792\n",
      "Epoch 147/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0745 - accuracy: 0.9792\n",
      "Epoch 148/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0742 - accuracy: 0.9791\n",
      "Epoch 149/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.9794\n",
      "Epoch 150/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9795\n",
      "Epoch 151/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0729 - accuracy: 0.9798\n",
      "Epoch 152/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9797\n",
      "Epoch 153/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9800\n",
      "Epoch 154/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.9799\n",
      "Epoch 155/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.9803\n",
      "Epoch 156/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0712 - accuracy: 0.9801\n",
      "Epoch 157/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9803\n",
      "Epoch 158/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.9805\n",
      "Epoch 159/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9805\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9806\n",
      "Epoch 161/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.9806\n",
      "Epoch 162/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0691 - accuracy: 0.9809\n",
      "Epoch 163/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0688 - accuracy: 0.9809\n",
      "Epoch 164/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.9809\n",
      "Epoch 165/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9813\n",
      "Epoch 166/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0678 - accuracy: 0.9812\n",
      "Epoch 167/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9811\n",
      "Epoch 168/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0672 - accuracy: 0.9813\n",
      "Epoch 169/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0668 - accuracy: 0.9814\n",
      "Epoch 170/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9815\n",
      "Epoch 171/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9816\n",
      "Epoch 172/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9819\n",
      "Epoch 173/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9818\n",
      "Epoch 174/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9817\n",
      "Epoch 175/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0650 - accuracy: 0.9818\n",
      "Epoch 176/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0647 - accuracy: 0.9821\n",
      "Epoch 177/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9821\n",
      "Epoch 178/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9821\n",
      "Epoch 179/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9823\n",
      "Epoch 180/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9824\n",
      "Epoch 181/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9824\n",
      "Epoch 182/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0629 - accuracy: 0.9825\n",
      "Epoch 183/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.9826\n",
      "Epoch 184/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0623 - accuracy: 0.9829\n",
      "Epoch 185/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0620 - accuracy: 0.9829\n",
      "Epoch 186/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9828\n",
      "Epoch 187/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9830\n",
      "Epoch 188/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.9833\n",
      "Epoch 189/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0609 - accuracy: 0.9832\n",
      "Epoch 190/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0607 - accuracy: 0.9832\n",
      "Epoch 191/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9834\n",
      "Epoch 192/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0602 - accuracy: 0.9834\n",
      "Epoch 193/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9837\n",
      "Epoch 194/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9837\n",
      "Epoch 195/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9838\n",
      "Epoch 196/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9837\n",
      "Epoch 197/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9837\n",
      "Epoch 198/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9840\n",
      "Epoch 199/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9838\n",
      "Epoch 200/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9839\n",
      "Epoch 201/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9842\n",
      "Epoch 202/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0576 - accuracy: 0.9841\n",
      "Epoch 203/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0573 - accuracy: 0.9845\n",
      "Epoch 204/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0571 - accuracy: 0.9845\n",
      "Epoch 205/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9844\n",
      "Epoch 206/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9844\n",
      "Epoch 207/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0564 - accuracy: 0.9846\n",
      "Epoch 208/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9844\n",
      "Epoch 209/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9846\n",
      "Epoch 210/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0558 - accuracy: 0.9848\n",
      "Epoch 211/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0554 - accuracy: 0.9848\n",
      "Epoch 212/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0553 - accuracy: 0.9849\n",
      "Epoch 213/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9847\n",
      "Epoch 214/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0548 - accuracy: 0.9851\n",
      "Epoch 215/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.9851\n",
      "Epoch 216/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0544 - accuracy: 0.9850\n",
      "Epoch 217/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.9852\n",
      "Epoch 218/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0539 - accuracy: 0.9853\n",
      "Epoch 219/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0537 - accuracy: 0.9853\n",
      "Epoch 220/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0535 - accuracy: 0.9853\n",
      "Epoch 221/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0532 - accuracy: 0.9855\n",
      "Epoch 222/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0530 - accuracy: 0.9855\n",
      "Epoch 223/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0528 - accuracy: 0.9857\n",
      "Epoch 224/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.9857\n",
      "Epoch 225/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9860\n",
      "Epoch 226/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0522 - accuracy: 0.9858\n",
      "Epoch 227/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0520 - accuracy: 0.9859\n",
      "Epoch 228/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.9859\n",
      "Epoch 229/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.9863\n",
      "Epoch 230/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0514 - accuracy: 0.9860\n",
      "Epoch 231/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0512 - accuracy: 0.9863\n",
      "Epoch 232/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0510 - accuracy: 0.9864\n",
      "Epoch 233/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0508 - accuracy: 0.9863\n",
      "Epoch 234/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0506 - accuracy: 0.9863\n",
      "Epoch 235/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.9864\n",
      "Epoch 236/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9866\n",
      "Epoch 237/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0500 - accuracy: 0.9867\n",
      "Epoch 238/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0498 - accuracy: 0.9867\n",
      "Epoch 239/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0496 - accuracy: 0.9867\n",
      "Epoch 240/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0494 - accuracy: 0.9868\n",
      "Epoch 241/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0492 - accuracy: 0.9869\n",
      "Epoch 242/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0490 - accuracy: 0.9870\n",
      "Epoch 243/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0488 - accuracy: 0.9871\n",
      "Epoch 244/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.9872\n",
      "Epoch 245/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0485 - accuracy: 0.9872\n",
      "Epoch 246/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.9871\n",
      "Epoch 247/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0481 - accuracy: 0.9870\n",
      "Epoch 248/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9874\n",
      "Epoch 249/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9876\n",
      "Epoch 250/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0475 - accuracy: 0.9872\n",
      "Epoch 251/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0474 - accuracy: 0.9876\n",
      "Epoch 252/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.9876\n",
      "Epoch 253/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9877\n",
      "Epoch 254/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.9877\n",
      "Epoch 255/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0467 - accuracy: 0.9877\n",
      "Epoch 256/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.9879\n",
      "Epoch 257/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0463 - accuracy: 0.9880\n",
      "Epoch 258/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0461 - accuracy: 0.9878\n",
      "Epoch 259/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0459 - accuracy: 0.9878\n",
      "Epoch 260/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0458 - accuracy: 0.9881\n",
      "Epoch 261/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0456 - accuracy: 0.9879\n",
      "Epoch 262/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0455 - accuracy: 0.9882\n",
      "Epoch 263/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0453 - accuracy: 0.9882\n",
      "Epoch 264/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9882\n",
      "Epoch 265/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0449 - accuracy: 0.9886\n",
      "Epoch 266/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0447 - accuracy: 0.9885\n",
      "Epoch 267/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0446 - accuracy: 0.9885\n",
      "Epoch 268/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.9885\n",
      "Epoch 269/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9884\n",
      "Epoch 270/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0441 - accuracy: 0.9884\n",
      "Epoch 271/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0440 - accuracy: 0.9886\n",
      "Epoch 272/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0438 - accuracy: 0.9888\n",
      "Epoch 273/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0436 - accuracy: 0.9887\n",
      "Epoch 274/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0435 - accuracy: 0.9887\n",
      "Epoch 275/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9888\n",
      "Epoch 276/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0432 - accuracy: 0.9890\n",
      "Epoch 277/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0430 - accuracy: 0.9889\n",
      "Epoch 278/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.9893\n",
      "Epoch 279/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9890\n",
      "Epoch 280/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0426 - accuracy: 0.9889\n",
      "Epoch 281/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0424 - accuracy: 0.9891\n",
      "Epoch 282/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0423 - accuracy: 0.9891\n",
      "Epoch 283/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0421 - accuracy: 0.9894\n",
      "Epoch 284/300\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0419 - accuracy: 0.9894\n",
      "Epoch 285/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9894\n",
      "Epoch 286/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0416 - accuracy: 0.9895\n",
      "Epoch 287/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.9893\n",
      "Epoch 288/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0413 - accuracy: 0.9894\n",
      "Epoch 289/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.9896\n",
      "Epoch 290/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.9895\n",
      "Epoch 291/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.9896\n",
      "Epoch 292/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9898\n",
      "Epoch 293/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.9895\n",
      "Epoch 294/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0405 - accuracy: 0.9899\n",
      "Epoch 295/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0403 - accuracy: 0.9899\n",
      "Epoch 296/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0402 - accuracy: 0.9901\n",
      "Epoch 297/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0401 - accuracy: 0.9899\n",
      "Epoch 298/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.9901\n",
      "Epoch 299/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.9900\n",
      "Epoch 300/300\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0396 - accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c092f142e0>"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wihtout_hm = get_model()\n",
    "model_wihtout_hm.fit(X_train_normalized, y_train, epochs = 300, verbose=1, batch_size=128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0842 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0841875821352005, 0.9750000238418579]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wihtout_hm.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 983us/step - loss: 0.0816 - accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0816257894039154, 0.9753999710083008]"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hm.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us predict for the first image in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 902us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.5752100e-01, 8.7638944e-02, 9.1932184e-01, ..., 9.9999988e-01,\n",
       "        9.7508371e-01, 9.9600530e-01],\n",
       "       [9.3946820e-01, 9.9903935e-01, 9.9999982e-01, ..., 3.1687628e-07,\n",
       "        9.9383855e-01, 7.5268814e-05],\n",
       "       [5.8856107e-02, 9.9974740e-01, 4.8162958e-01, ..., 6.4746690e-01,\n",
       "        9.1900593e-01, 8.7856911e-02],\n",
       "       ...,\n",
       "       [9.1111928e-02, 3.4603960e-04, 6.2518883e-03, ..., 9.7027290e-01,\n",
       "        9.9050385e-01, 9.9879086e-01],\n",
       "       [2.7950111e-01, 7.3659234e-03, 5.8780116e-04, ..., 1.3471374e-02,\n",
       "        9.9686825e-01, 8.1832679e-03],\n",
       "       [4.8747963e-01, 2.1828068e-03, 9.6400297e-01, ..., 7.0892975e-07,\n",
       "        1.5583545e-01, 6.1287362e-02]], dtype=float32)"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hm.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c0941c10d0>"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 884us/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model_hm.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0004911e-01, 1.8262267e-03, 1.9984832e-01, 9.9306405e-01,\n",
       "       7.8678140e-06, 5.6786299e-02, 1.8056544e-06, 9.9999869e-01,\n",
       "       4.3653762e-01, 4.6398658e-01], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted[0]\n",
    "# Displays the probability score for each class label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_predicted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the predicted probabilities into actual class labels to contruct confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0004911e-01, 1.8262267e-03, 1.9984832e-01, 9.9306405e-01,\n",
       "        7.8678140e-06, 5.6786299e-02, 1.8056544e-06, 9.9999869e-01,\n",
       "        4.3653762e-01, 4.6398658e-01],\n",
       "       [3.5234094e-03, 8.6605072e-01, 9.9999726e-01, 9.9342388e-01,\n",
       "        1.2409489e-10, 4.8146451e-01, 3.8505495e-03, 1.8282478e-06,\n",
       "        8.6112589e-01, 1.4091442e-07],\n",
       "       [4.1994452e-04, 9.9706542e-01, 2.2127745e-01, 4.4714242e-02,\n",
       "        1.7070711e-02, 3.4771860e-03, 8.4775090e-03, 2.3177141e-01,\n",
       "        1.7130309e-01, 2.7160048e-03],\n",
       "       [9.9997437e-01, 5.7680850e-06, 9.1143566e-01, 7.5162351e-03,\n",
       "        1.1362774e-05, 4.0780783e-02, 6.9209534e-01, 7.9200798e-01,\n",
       "        1.5428960e-02, 1.0488731e-01],\n",
       "       [4.1146874e-03, 2.7437938e-05, 1.9890279e-02, 2.3822784e-03,\n",
       "        9.9962533e-01, 4.3750554e-02, 1.1046550e-01, 7.4856889e-01,\n",
       "        4.1398376e-02, 9.7764587e-01]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]\n",
    "y_predicted_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
       "array([[ 966,    0,    2,    1,    1,    2,    3,    1,    3,    1],\n",
       "       [   0, 1123,    2,    1,    0,    1,    3,    0,    5,    0],\n",
       "       [   2,    4,  996,    3,    2,    0,    2,   14,    9,    0],\n",
       "       [   0,    1,    3,  989,    0,    1,    0,    5,    9,    2],\n",
       "       [   1,    0,    3,    1,  953,    1,    7,    3,    2,   11],\n",
       "       [   4,    0,    0,   13,    1,  848,    5,    3,   13,    5],\n",
       "       [   7,    2,    4,    1,    4,    5,  927,    3,    5,    0],\n",
       "       [   0,    5,    7,    3,    1,    0,    0, 1005,    2,    5],\n",
       "       [   4,    1,    1,    5,    3,    4,    1,    6,  948,    1],\n",
       "       [   2,    4,    0,    6,   10,    7,    0,   15,    7,  958]])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = tf.math.confusion_matrix(labels = y_test, predictions = y_predicted_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt = 'd')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
