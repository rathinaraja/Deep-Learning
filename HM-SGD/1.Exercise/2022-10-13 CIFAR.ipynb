{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ2um3Oau3ET"
   },
   "source": [
    "<h2 style=\"color:blue\" align=\"center\">Plain Deep Neural Network (DNN) on CIFAR</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dANJl4o8u3EY"
   },
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P63KnoDvu3EY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import time, math \n",
    "\n",
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import Callback, CSVLogger "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii6aMjDDu3Ea"
   },
   "source": [
    "#### Load and split the dataset into training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhGMMeWPu3Ea"
   },
   "source": [
    "CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1wBeG5Puu3Eb"
   },
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e04KvT7bu3Eb"
   },
   "source": [
    "CIFAR 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r1tq7jduu3Ec"
   },
   "outputs": [],
   "source": [
    "#(X_train,y_train),(X_test,y_test) = keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PDgUz0F5obY"
   },
   "source": [
    "Here we see there are 50000 training images and 1000 test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9gz-ukeu3Ec"
   },
   "source": [
    "#### Normalize the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "plStj22pu3Ed"
   },
   "outputs": [],
   "source": [
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZVL6i6rH2lmv"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czzweO3tu3Ee"
   },
   "source": [
    "#### Define DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z75xiuVqu3Ef"
   },
   "outputs": [],
   "source": [
    "python_random.seed(3)\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(13)\n",
    "opti_name = ''\n",
    "\n",
    "def get_model(): \n",
    "    model = Sequential([ \n",
    "          Flatten(input_shape=(32,32,3)),\n",
    "          Dense(3000, activation = 'relu'),\n",
    "          Dense(1000, activation = 'relu'),\n",
    "          # For CIFAR-10\n",
    "          Dense(10, activation = 'softmax')\n",
    "          # For CIFAR-100\n",
    "          #Dense(100, activation = 'softmax')\n",
    "    ]) \n",
    "    \n",
    "    global opti_name\n",
    "    \n",
    "    # General SGD\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    #opti_name = 'SGD'\n",
    "    \n",
    "    # SGD with momentum\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01, momentum=0.6)\n",
    "    #opti_name = 'SGD with momentum'\n",
    "    \n",
    "    # SGD with Nesterov momentum \n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01, momentum=0.6, nesterov=True)\n",
    "    #opti_name = 'SGD with Nesterov momentum'\n",
    "    \n",
    "    # RMSprop \n",
    "    #opti = keras.optimizers.RMSprop(learning_rate=0.001, momentum=0.6)\n",
    "    #opti_name = 'RMSprop'\n",
    "    \n",
    "    # Adam\n",
    "    opti = keras.optimizers.Adam(learning_rate=0.001) \n",
    "    opti_name = 'Adam'\n",
    "    \n",
    "    # Adamax\n",
    "    #opti = keras.optimizers.Adamax(learning_rate=0.001) \n",
    "    #opti_name = 'Adamax'\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = opti,\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f5rtWenu3Ef"
   },
   "source": [
    "#### Custom callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWo_NQOwu3Eg"
   },
   "source": [
    "For generic optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "U6OElGQtu3Eg"
   },
   "outputs": [],
   "source": [
    "# Get the best of base-line model and set it as stopping criteria in HM-based model\n",
    "generic_best = 0\n",
    "\n",
    "class CustomCallbackGeneric(Callback):   \n",
    "    # Training stop criteria\n",
    "    stop_at = 0.99\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global generic_best\n",
    "        acc = round(logs.get('accuracy'), 4)  \n",
    "        \n",
    "        if epoch == 0:\n",
    "            generic_best = acc             \n",
    "        \n",
    "        if epoch > 0 and acc > generic_best :\n",
    "            generic_best = acc  \n",
    "            \n",
    "        if(acc > self.stop_at):  \n",
    "            self.model.stop_training = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg30yzj-u3Eg"
   },
   "source": [
    "For HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sfHN9hIdu3Eg"
   },
   "outputs": [],
   "source": [
    "class CustomCallbackHM(Callback):   \n",
    "    initial_weights = 0\n",
    "    previous_weights = 0\n",
    "    call_hm = 0     \n",
    "    r = 1\n",
    "    # r=0 no HM based, r=1 HM based\n",
    "     \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.initial_weights = model_hm.get_weights() \n",
    "        self.initial_weights = np.array(self.initial_weights,dtype=object)\n",
    "        self.previous_weights = self.initial_weights\n",
    "        # Harmonic mean based weights calculation\n",
    "        self.call_hm = np.vectorize(self.apply_hm)  \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "         # Set the stopping criteria at (stop_at) the MAE obtained from the baseline model \n",
    "        global generic_best \n",
    "        \n",
    "        num_layers = len(model_hm.layers)-1  \n",
    "        current_weights = model_hm.get_weights() \n",
    "        current_weights = np.array(current_weights, dtype=object)       \n",
    "\n",
    "        for i in range(num_layers):  \n",
    "            # Harmonic mean based weights calculation \n",
    "            tensor1 = tf.convert_to_tensor(self.previous_weights[i*2])\n",
    "            tensor2 = tf.convert_to_tensor(current_weights[i*2])\n",
    "            current_weights[i*2] = self.call_hm(tensor1, tensor2)   \n",
    "               \n",
    "        # Updating the model with new weights   \n",
    "        model_hm.set_weights(current_weights.tolist())\n",
    "        self.previous_weights = current_weights\n",
    "        \n",
    "         # Stopping criteria\n",
    "        if(round(logs.get('accuracy')) > generic_best): \n",
    "            self.model.stop_training = True\n",
    "        \n",
    "    def apply_hm(self, v1, v2):     \n",
    "        if v1==0 or v2==0:\n",
    "            return v2\n",
    "        elif v1>0 and v2>0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            min1 = min(v1,v2)\n",
    "            diff = abs(hm-min1) * self.r\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        elif v1<0 and v2<0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            max1 = max(v1,v2)\n",
    "            diff = abs(hm-max1) * self.r\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        else:\n",
    "            return v2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLpBFwlPu3Eh"
   },
   "source": [
    "To record loss and accuracy in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L-v9BAOWu3Eh"
   },
   "outputs": [],
   "source": [
    "logger_generic_model = CSVLogger('3.Generic_model_CIFAR.csv', append=False, separator=',')\n",
    "logger_hm_model = CSVLogger('3.HM_model_CIFAR.csv', append=False, separator=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQK_pggku3Ei"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a model to assign same weights to model with and without HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model() \n",
    "weights = model.get_weights() \n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62pnBX6bu3Ei"
   },
   "source": [
    "Generic opimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr3H0_aZu3Ej",
    "outputId": "fba700c7-daa9-4eef-cba3-c4586325a003",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.3993 - accuracy: 0.1035\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 9s 9s/step - loss: 17.8830 - accuracy: 0.1037\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 10s 10s/step - loss: 14.2866 - accuracy: 0.1503\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 9s 9s/step - loss: 9.7659 - accuracy: 0.0999\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 9s 9s/step - loss: 7.8828 - accuracy: 0.1025\n",
      "Execution time: 49.85312223434448 seconds\n",
      "\n",
      "Generic optimizer best Accuracy is : 0.15\n"
     ]
    }
   ],
   "source": [
    "model_wihtout_hm = get_model()\n",
    "model_wihtout_hm.set_weights(weights) \n",
    "st = time.time() \n",
    "model_wihtout_hm.fit(X_train_normalized, y_train, epochs = num_epochs, verbose=1, callbacks=[CustomCallbackGeneric(), logger_generic_model], batch_size = X_train.shape[0]) \n",
    "et = time.time()\n",
    "elapsed_time = round(et - st, 4)\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "print('\\nGeneric optimizer best Accuracy is :', cb.generic_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpwj5UDxu3Ej"
   },
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC_LxQAmu3Ek",
    "outputId": "959ad653-1cc0-4331-964c-f7a26c8a8c89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 21s 21s/step - loss: 2.3993 - accuracy: 0.1035\n",
      "Execution time: 21.878639459609985 seconds\n"
     ]
    }
   ],
   "source": [
    "model_hm = get_model()\n",
    "model_hm.set_weights(weights) \n",
    "st = time.time()\n",
    "model_hm.fit(X_train_normalized, y_train, epochs = num_epochs, verbose=1, callbacks=[CustomCallbackHM(),logger_hm_model], batch_size = X_train.shape[0]) \n",
    "et = time.time()\n",
    "elapsed_time = round(et - st, 4)\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aly88iAou3Ek"
   },
   "source": [
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P5k_wdQ5u3Ek",
    "outputId": "d2a82c48-0b4f-433b-a3ea-e08e61e5db47",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 3000)              9219000   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1000)              3001000   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,230,010\n",
      "Trainable params: 12,230,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_hm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic optimizer vs HM-based optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"3.Generic_model_MNIST.csv\")\n",
    "df2 = pd.read_csv(\"3.HM_model_MNIST.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = range(0, df1.shape[0])\n",
    "x2 = range(0, df2.shape[0])\n",
    "y1 = df1['accuracy'] \n",
    "y2 = df2['accuracy']  \n",
    "plt.figure(figsize = (3,2), dpi = 200)\n",
    "plt.plot(x1, y1, \"r-\", label = opti_name, linewidth = 0.8, alpha = 0.7)\n",
    "plt.plot(x2, y2, \"k:\", label = 'HM-based ' + opti_name, linewidth = 1, alpha = 0.9) \n",
    "plt.ylabel('Accuracy' , fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xlabel('Epoch', fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "#plt.title(\"Loss\", fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.yticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.tight_layout()\n",
    "plt.legend(prop={'size': 5})\n",
    "#plt.savefig(\"graph.png\",bbox_inches='tight',dpi=(300)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = range(0, df1.shape[0])\n",
    "x2 = range(0, df2.shape[0])\n",
    "y1 = df1['loss'] \n",
    "y2 = df2['loss']  \n",
    "plt.figure(figsize = (3,2), dpi = 200)\n",
    "plt.plot(x1, y1, \"r-\", label = opti_name, linewidth = 0.8, alpha = 0.7)\n",
    "plt.plot(x2, y2, \"k:\", label = 'HM-based ' + opti_name, linewidth = 1, alpha = 0.9) \n",
    "plt.ylabel('Loss' , fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xlabel('Epoch', fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "#plt.title(\"MAE\", fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.yticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.tight_layout()\n",
    "plt.legend(prop={'size': 5})\n",
    "#plt.savefig(\"graph.png\",bbox_inches='tight',dpi=(300)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiCK5k2Bu3Ek"
   },
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB6FS5Hpu3Ek"
   },
   "source": [
    "Generic opimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1HMuXLPu3El",
    "outputId": "5cb866ab-a89d-4c87-95d4-fcfb797cd8e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 4.7155 - accuracy: 0.1003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.715517997741699, 0.10029999911785126]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wihtout_hm.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k53-C48xu3El"
   },
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EyuXtuC9u3El",
    "outputId": "e5420f46-e500-4118-cabd-42e64da4c751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 6.0043 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.004293441772461, 0.10000000149011612]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hm.evaluate(X_test_normalized, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CIFAR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
