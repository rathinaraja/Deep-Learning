{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"center\">Deep Neural Network (DNN) on MNIST</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time, math \n",
    "\n",
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "from keras.callbacks import Callback, CSVLogger "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and split the dataset into training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST - Handwritten digits recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST - Fashion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train,y_train),(X_test,y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28 * 28)\n",
    "X_test_flattened = X_test.reshape(len(X_test),  28 * 28) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train_flattened / 255\n",
    "X_test_normalized = X_test_flattened / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define DNN model with two layers, optimizer, metrics, and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as python_random\n",
    "python_random.seed(3)\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "def get_model(): \n",
    "    model = Sequential([\n",
    "        # input layer 784 neurons to first hidden layer with 64 neurons\n",
    "        Dense(64, input_shape = (784,), activation='relu'), \n",
    "        # first hidden layer to second hidden layer\n",
    "        Dense(64, activation='relu'),  \n",
    "        # Output layer with 10 neurons\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # General SGD\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    \n",
    "    # SGD with momentum\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01, momentum=0.6)\n",
    "    \n",
    "    # SGD with Nesterov momentum \n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01, momentum=0.6, nesterov=True)\n",
    "    \n",
    "    # RMSprop \n",
    "    #opti = keras.optimizers.RMSprop(learning_rate=0.001, momentum=0.6)\n",
    "    \n",
    "    # Adam\n",
    "    opti = keras.optimizers.Adam(learning_rate=0.001) \n",
    "    \n",
    "    # Adamax\n",
    "    #opti = keras.optimizers.Adamax(learning_rate=0.001) \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = opti,\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For generic optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallbackGeneric(Callback):  \n",
    "    # Training stop criteria\n",
    "    stop_at = 0.99\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')> self.stop_at):  \n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallbackHM(Callback):  \n",
    "    # Stop the algorithm when the following accuracy reached \n",
    "    stop_at = 0.995  \n",
    "    \n",
    "    initial_weights = 0\n",
    "    previous_weights = 0\n",
    "    call_hm = 0 \n",
    "     \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.initial_weights = model_hm.get_weights() \n",
    "        self.initial_weights = np.array(self.initial_weights,dtype=object)\n",
    "        self.previous_weights = self.initial_weights\n",
    "        # Harmonic mean based weights calculation\n",
    "        self.call_hm = np.vectorize(self.apply_hm)  \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Training stop criteria\n",
    "        if(logs.get('accuracy')> self.stop_at):  \n",
    "            self.model.stop_training = True\n",
    "        \n",
    "        num_layers = len(model_hm.layers)  \n",
    "        current_weights = model_hm.get_weights()\n",
    "        current_weights = np.array(current_weights,dtype=object)        \n",
    "\n",
    "        for i in range(num_layers):  \n",
    "            # Harmonic mean based weights calculation\n",
    "            tensor1 = tf.convert_to_tensor(self.previous_weights[i*2])\n",
    "            tensor2 = tf.convert_to_tensor(current_weights[i*2])\n",
    "            current_weights[i*2] = self.call_hm(tensor1, tensor2)   \n",
    "            \n",
    "        # Updating the model with new weights\n",
    "        model_hm.set_weights(current_weights.tolist())\n",
    "        self.previous_weights = current_weights\n",
    "        \n",
    "    def apply_hm(self, v1, v2):     \n",
    "        if v1==0 or v2==0:\n",
    "            return v2\n",
    "        elif v1>0 and v2>0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            min1 = min(v1,v2)\n",
    "            diff = abs(hm-min1)\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        elif v1<0 and v2<0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            max1 = max(v1,v2)\n",
    "            diff = abs(hm-max1)\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        else:\n",
    "            return v2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To record loss and accuracy in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_generic_model = CSVLogger('Generic_model_MNIST.csv', append=False, separator=',')\n",
    "logger_hm_model = CSVLogger('HM_model_MNIST.csv', append=False, separator=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a model to assign same weights to model with and without HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model() \n",
    "weights = model.get_weights() \n",
    "model_wihtout_hm = get_model()\n",
    "model_wihtout_hm.set_weights(weights) \n",
    "model_hm = get_model()\n",
    "model_hm.set_weights(weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 2.3563 - accuracy: 0.1617\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.2024 - accuracy: 0.2233\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.0940 - accuracy: 0.2942\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.9998 - accuracy: 0.3410\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.9052 - accuracy: 0.3736\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.8137 - accuracy: 0.4196\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.7220 - accuracy: 0.4589\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.6288 - accuracy: 0.4893\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.5386 - accuracy: 0.5350\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.4545 - accuracy: 0.5891\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.3776 - accuracy: 0.6202\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.3082 - accuracy: 0.6340\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.2454 - accuracy: 0.6400\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.1879 - accuracy: 0.6414\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.1358 - accuracy: 0.6417\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.0886 - accuracy: 0.6442\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.0466 - accuracy: 0.6497\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.0103 - accuracy: 0.6537\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9775 - accuracy: 0.6600\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.9469 - accuracy: 0.6695\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9194 - accuracy: 0.6802\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8950 - accuracy: 0.6903\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.8732 - accuracy: 0.6973\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8536 - accuracy: 0.7039\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.8353 - accuracy: 0.7098\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.8178 - accuracy: 0.7152\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8017 - accuracy: 0.7195\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.7869 - accuracy: 0.7229\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.7732 - accuracy: 0.7262\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7602 - accuracy: 0.7311\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7473 - accuracy: 0.7378\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.7349 - accuracy: 0.7455\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.7233 - accuracy: 0.7523\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7124 - accuracy: 0.7572\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7021 - accuracy: 0.7619\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.6918 - accuracy: 0.7667\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6816 - accuracy: 0.7709\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6719 - accuracy: 0.7739\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6625 - accuracy: 0.7765\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6535 - accuracy: 0.7793\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.6448 - accuracy: 0.7835\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6367 - accuracy: 0.7873\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6293 - accuracy: 0.7905\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.6222 - accuracy: 0.7931\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6153 - accuracy: 0.7952\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.6087 - accuracy: 0.7972\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6024 - accuracy: 0.7984\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.5964 - accuracy: 0.8001\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5905 - accuracy: 0.8021\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5849 - accuracy: 0.8044\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5796 - accuracy: 0.8063\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.5744 - accuracy: 0.8082\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5692 - accuracy: 0.8099\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5643 - accuracy: 0.8117\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5595 - accuracy: 0.8129\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.5549 - accuracy: 0.8141\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5504 - accuracy: 0.8159\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.5462 - accuracy: 0.8171\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5420 - accuracy: 0.8182\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5380 - accuracy: 0.8193\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5341 - accuracy: 0.8209\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5303 - accuracy: 0.8218\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5266 - accuracy: 0.8227\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5230 - accuracy: 0.8241\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5196 - accuracy: 0.8256\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5162 - accuracy: 0.8266\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.5129 - accuracy: 0.8275\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5097 - accuracy: 0.8285\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5066 - accuracy: 0.8294\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5036 - accuracy: 0.8305\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5007 - accuracy: 0.8316\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4978 - accuracy: 0.8324\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4950 - accuracy: 0.8332\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4923 - accuracy: 0.8339\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4897 - accuracy: 0.8348\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4871 - accuracy: 0.8354\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.4846 - accuracy: 0.8365\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4822 - accuracy: 0.8372\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4798 - accuracy: 0.8374\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4775 - accuracy: 0.8382\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4752 - accuracy: 0.8386\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.4730 - accuracy: 0.8391\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4708 - accuracy: 0.8397\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4687 - accuracy: 0.8403\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4666 - accuracy: 0.8411\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.4645 - accuracy: 0.8417\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4625 - accuracy: 0.8422\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4606 - accuracy: 0.8428\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4587 - accuracy: 0.8434\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4568 - accuracy: 0.8441\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4549 - accuracy: 0.8444\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4531 - accuracy: 0.8448\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4513 - accuracy: 0.8453\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4496 - accuracy: 0.8461\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4479 - accuracy: 0.8466\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4461 - accuracy: 0.8468\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4445 - accuracy: 0.8473\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4428 - accuracy: 0.8480\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.4412 - accuracy: 0.8488\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4395 - accuracy: 0.8493\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4379 - accuracy: 0.8497\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4364 - accuracy: 0.8505\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.4348 - accuracy: 0.8510\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4333 - accuracy: 0.8514\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.4318 - accuracy: 0.8518\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4303 - accuracy: 0.8521\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.4288 - accuracy: 0.8527\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.4273 - accuracy: 0.8531\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.4259 - accuracy: 0.8534\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.4245 - accuracy: 0.8539\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4231 - accuracy: 0.8543\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4218 - accuracy: 0.8549\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4205 - accuracy: 0.8550\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.4193 - accuracy: 0.8556\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.4182 - accuracy: 0.8555\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.4173 - accuracy: 0.8561\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4161 - accuracy: 0.8561\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4145 - accuracy: 0.8566\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.4128 - accuracy: 0.8572\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4117 - accuracy: 0.8576\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4108 - accuracy: 0.8579\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.4098 - accuracy: 0.8586\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.4084 - accuracy: 0.8588\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.4070 - accuracy: 0.8593\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4059 - accuracy: 0.8596\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.4051 - accuracy: 0.8597\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4040 - accuracy: 0.8601\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.4027 - accuracy: 0.8607\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4015 - accuracy: 0.8609\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4006 - accuracy: 0.8615\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3997 - accuracy: 0.8617\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3987 - accuracy: 0.8621\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3976 - accuracy: 0.8625\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3965 - accuracy: 0.8628\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3955 - accuracy: 0.8631\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.3948 - accuracy: 0.8633\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3940 - accuracy: 0.8636\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3934 - accuracy: 0.8641\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3928 - accuracy: 0.8638\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3921 - accuracy: 0.8648\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3910 - accuracy: 0.8646\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3895 - accuracy: 0.8652\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.3882 - accuracy: 0.8655\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3876 - accuracy: 0.8654\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3870 - accuracy: 0.8662\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3861 - accuracy: 0.8661\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.3849 - accuracy: 0.8663\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.3840 - accuracy: 0.8669\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.3834 - accuracy: 0.8667\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3826 - accuracy: 0.8676\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.3816 - accuracy: 0.8674\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3807 - accuracy: 0.8677\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3800 - accuracy: 0.8680\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3793 - accuracy: 0.8681\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3784 - accuracy: 0.8687\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.3775 - accuracy: 0.8688\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3768 - accuracy: 0.8689\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3762 - accuracy: 0.8691\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3754 - accuracy: 0.8691\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3745 - accuracy: 0.8700\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3737 - accuracy: 0.8703\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3730 - accuracy: 0.8703\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3724 - accuracy: 0.8703\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3717 - accuracy: 0.8703\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3709 - accuracy: 0.8706\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3701 - accuracy: 0.8715\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.3694 - accuracy: 0.8714\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3687 - accuracy: 0.8719\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.3681 - accuracy: 0.8718\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3673 - accuracy: 0.8721\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3666 - accuracy: 0.8725\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3659 - accuracy: 0.8727\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3652 - accuracy: 0.8729\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3646 - accuracy: 0.8729\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3639 - accuracy: 0.8732\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3632 - accuracy: 0.8735\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3626 - accuracy: 0.8739\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.3619 - accuracy: 0.8738\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3612 - accuracy: 0.8741\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3607 - accuracy: 0.8740\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3602 - accuracy: 0.8745\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.3598 - accuracy: 0.8739\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.3598 - accuracy: 0.8743\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3604 - accuracy: 0.8730\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3610 - accuracy: 0.8734\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3602 - accuracy: 0.8727\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3575 - accuracy: 0.8754\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.3557 - accuracy: 0.8755\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3563 - accuracy: 0.8745\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.3566 - accuracy: 0.8753\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3550 - accuracy: 0.8750\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3534 - accuracy: 0.8767\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.3537 - accuracy: 0.8766\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3538 - accuracy: 0.8756\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.3523 - accuracy: 0.8769\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.3512 - accuracy: 0.8773\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.3514 - accuracy: 0.8766\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.3511 - accuracy: 0.8777\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3499 - accuracy: 0.8771\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.3491 - accuracy: 0.8778\n",
      "Execution time: 40.449440479278564 seconds\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "model_wihtout_hm.fit(X_train_normalized, y_train, epochs = 200, verbose=1, callbacks=[CustomCallbackGeneric(), logger_generic_model], batch_size = X_train.shape[0]) \n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 2.3563 - accuracy: 0.1617\n",
      "Epoch 2/175\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 2.1510 - accuracy: 0.2585\n",
      "Epoch 3/175\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 2.0183 - accuracy: 0.3388\n",
      "Epoch 4/175\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.8870 - accuracy: 0.3788\n",
      "Epoch 5/175\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.7588 - accuracy: 0.4441\n",
      "Epoch 6/175\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.6277 - accuracy: 0.4893\n",
      "Epoch 7/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.5041 - accuracy: 0.5491\n",
      "Epoch 8/175\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.3952 - accuracy: 0.6077\n",
      "Epoch 9/175\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.2987 - accuracy: 0.6316\n",
      "Epoch 10/175\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.2150 - accuracy: 0.6418\n",
      "Epoch 11/175\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.1419 - accuracy: 0.6447\n",
      "Epoch 12/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.0778 - accuracy: 0.6452\n",
      "Epoch 13/175\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.0221 - accuracy: 0.6488\n",
      "Epoch 14/175\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.9750 - accuracy: 0.6544\n",
      "Epoch 15/175\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9358 - accuracy: 0.6646\n",
      "Epoch 16/175\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.9013 - accuracy: 0.6810\n",
      "Epoch 17/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8715 - accuracy: 0.6950\n",
      "Epoch 18/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.8452 - accuracy: 0.7042\n",
      "Epoch 19/175\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.8226 - accuracy: 0.7100\n",
      "Epoch 20/175\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.8021 - accuracy: 0.7151\n",
      "Epoch 21/175\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.7827 - accuracy: 0.7190\n",
      "Epoch 22/175\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7648 - accuracy: 0.7240\n",
      "Epoch 23/175\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7486 - accuracy: 0.7306\n",
      "Epoch 24/175\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.7336 - accuracy: 0.7400\n",
      "Epoch 25/175\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.7187 - accuracy: 0.7505\n",
      "Epoch 26/175\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.7045 - accuracy: 0.7579\n",
      "Epoch 27/175\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6916 - accuracy: 0.7650\n",
      "Epoch 28/175\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.6793 - accuracy: 0.7700\n",
      "Epoch 29/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.6671 - accuracy: 0.7746\n",
      "Epoch 30/175\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.6554 - accuracy: 0.7768\n",
      "Epoch 31/175\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.6449 - accuracy: 0.7793\n",
      "Epoch 32/175\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6346 - accuracy: 0.7840\n",
      "Epoch 33/175\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.6248 - accuracy: 0.7891\n",
      "Epoch 34/175\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.6156 - accuracy: 0.7935\n",
      "Epoch 35/175\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.6070 - accuracy: 0.7963\n",
      "Epoch 36/175\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5985 - accuracy: 0.7985\n",
      "Epoch 37/175\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5906 - accuracy: 0.7993\n",
      "Epoch 38/175\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5834 - accuracy: 0.8013\n",
      "Epoch 39/175\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.5765 - accuracy: 0.8041\n",
      "Epoch 40/175\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5696 - accuracy: 0.8069\n",
      "Epoch 41/175\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5632 - accuracy: 0.8095\n",
      "Epoch 42/175\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.5572 - accuracy: 0.8119\n",
      "Epoch 43/175\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.5511 - accuracy: 0.8137\n",
      "Epoch 44/175\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5457 - accuracy: 0.8155\n",
      "Epoch 45/175\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5404 - accuracy: 0.8170\n",
      "Epoch 46/175\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5351 - accuracy: 0.8193\n",
      "Epoch 47/175\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.5303 - accuracy: 0.8215\n",
      "Epoch 48/175\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.5257 - accuracy: 0.8230\n",
      "Epoch 49/175\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.5211 - accuracy: 0.8242\n",
      "Epoch 50/175\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5167 - accuracy: 0.8251\n",
      "Epoch 51/175\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.5126 - accuracy: 0.8266\n",
      "Epoch 52/175\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.5084 - accuracy: 0.8280\n",
      "Epoch 53/175\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.5044 - accuracy: 0.8291\n",
      "Epoch 54/175\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5007 - accuracy: 0.8306\n",
      "Epoch 55/175\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4970 - accuracy: 0.8317\n",
      "Epoch 56/175\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.4935 - accuracy: 0.8326\n",
      "Epoch 57/175\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4901 - accuracy: 0.8340\n",
      "Epoch 58/175\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4868 - accuracy: 0.8347\n",
      "Epoch 59/175\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 0.4837 - accuracy: 0.8357\n",
      "Epoch 60/175\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.4808 - accuracy: 0.8367\n",
      "Epoch 61/175\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.4780 - accuracy: 0.8371\n",
      "Epoch 62/175\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.4755 - accuracy: 0.8385\n",
      "Epoch 63/175\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.4729 - accuracy: 0.8385\n",
      "Epoch 64/175\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.4700 - accuracy: 0.8401\n",
      "Epoch 65/175\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.4668 - accuracy: 0.8409\n",
      "Epoch 66/175\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4641 - accuracy: 0.8414\n",
      "Epoch 67/175\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4620 - accuracy: 0.8424\n",
      "Epoch 68/175\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.4600 - accuracy: 0.8423\n",
      "Epoch 69/175\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4578 - accuracy: 0.8440\n",
      "Epoch 70/175\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.4555 - accuracy: 0.8439\n",
      "Epoch 71/175\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.4538 - accuracy: 0.8451\n",
      "Epoch 72/175\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4527 - accuracy: 0.8443\n",
      "Epoch 73/175\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4512 - accuracy: 0.8456\n",
      "Epoch 74/175\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4478 - accuracy: 0.8464\n",
      "Epoch 75/175\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4446 - accuracy: 0.8482\n",
      "Epoch 76/175\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.4435 - accuracy: 0.8489\n",
      "Epoch 77/175\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.4423 - accuracy: 0.8482\n",
      "Epoch 78/175\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.4398 - accuracy: 0.8497\n",
      "Epoch 79/175\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.4376 - accuracy: 0.8503\n",
      "Epoch 80/175\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.4364 - accuracy: 0.8508\n",
      "Epoch 81/175\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.4345 - accuracy: 0.8517\n",
      "Epoch 82/175\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.4322 - accuracy: 0.8520\n",
      "Epoch 83/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4310 - accuracy: 0.8524\n",
      "Epoch 84/175\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4298 - accuracy: 0.8530\n",
      "Epoch 85/175\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.4276 - accuracy: 0.8534\n",
      "Epoch 86/175\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4257 - accuracy: 0.8540\n",
      "Epoch 87/175\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.4246 - accuracy: 0.8546\n",
      "Epoch 88/175\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4231 - accuracy: 0.8548\n",
      "Epoch 89/175\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.4213 - accuracy: 0.8551\n",
      "Epoch 90/175\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4200 - accuracy: 0.8558\n",
      "Epoch 91/175\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.4188 - accuracy: 0.8557\n",
      "Epoch 92/175\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.4172 - accuracy: 0.8568\n",
      "Epoch 93/175\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.4155 - accuracy: 0.8570\n",
      "Epoch 94/175\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.4143 - accuracy: 0.8575\n",
      "Epoch 95/175\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.4131 - accuracy: 0.8582\n",
      "Epoch 96/175\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4116 - accuracy: 0.8584\n",
      "Epoch 97/175\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.4102 - accuracy: 0.8586\n",
      "Epoch 98/175\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4090 - accuracy: 0.8594\n",
      "Epoch 99/175\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4079 - accuracy: 0.8593\n",
      "Epoch 100/175\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.4067 - accuracy: 0.8602\n",
      "Epoch 101/175\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.4054 - accuracy: 0.8602\n",
      "Epoch 102/175\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4043 - accuracy: 0.8608\n",
      "Epoch 103/175\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.4035 - accuracy: 0.8611\n",
      "Epoch 104/175\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4027 - accuracy: 0.8609\n",
      "Epoch 105/175\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.4025 - accuracy: 0.8613\n",
      "Epoch 106/175\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.4019 - accuracy: 0.8608\n",
      "Epoch 107/175\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.4016 - accuracy: 0.8621\n",
      "Epoch 108/175\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3993 - accuracy: 0.8620\n",
      "Epoch 109/175\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.3964 - accuracy: 0.8631\n",
      "Epoch 110/175\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.3947 - accuracy: 0.8634\n",
      "Epoch 111/175\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3946 - accuracy: 0.8637\n",
      "Epoch 112/175\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3946 - accuracy: 0.8641\n",
      "Epoch 113/175\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.3928 - accuracy: 0.8643\n",
      "Epoch 114/175\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3906 - accuracy: 0.8652\n",
      "Epoch 115/175\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3896 - accuracy: 0.8654\n",
      "Epoch 116/175\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.3894 - accuracy: 0.8655\n",
      "Epoch 117/175\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.3886 - accuracy: 0.8663\n",
      "Epoch 118/175\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3869 - accuracy: 0.8661\n",
      "Epoch 119/175\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.3855 - accuracy: 0.8671\n",
      "Epoch 120/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3848 - accuracy: 0.8670\n",
      "Epoch 121/175\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3842 - accuracy: 0.8672\n",
      "Epoch 122/175\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3831 - accuracy: 0.8676\n",
      "Epoch 123/175\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.3818 - accuracy: 0.8682\n",
      "Epoch 124/175\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3809 - accuracy: 0.8689\n",
      "Epoch 125/175\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3802 - accuracy: 0.8683\n",
      "Epoch 126/175\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3793 - accuracy: 0.8691\n",
      "Epoch 127/175\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.3782 - accuracy: 0.8690\n",
      "Epoch 128/175\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3771 - accuracy: 0.8696\n",
      "Epoch 129/175\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3763 - accuracy: 0.8698\n",
      "Epoch 130/175\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.3756 - accuracy: 0.8698\n",
      "Epoch 131/175\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.3748 - accuracy: 0.8703\n",
      "Epoch 132/175\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3739 - accuracy: 0.8705\n",
      "Epoch 133/175\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3728 - accuracy: 0.8710\n",
      "Epoch 134/175\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3718 - accuracy: 0.8713\n",
      "Epoch 135/175\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.3710 - accuracy: 0.8715\n",
      "Epoch 136/175\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.3703 - accuracy: 0.8718\n",
      "Epoch 137/175\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.3695 - accuracy: 0.8716\n",
      "Epoch 138/175\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.3686 - accuracy: 0.8721\n",
      "Epoch 139/175\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3677 - accuracy: 0.8722\n",
      "Epoch 140/175\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3668 - accuracy: 0.8730\n",
      "Epoch 141/175\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3659 - accuracy: 0.8732\n",
      "Epoch 142/175\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3651 - accuracy: 0.8731\n",
      "Epoch 143/175\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3644 - accuracy: 0.8735\n",
      "Epoch 144/175\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3637 - accuracy: 0.8736\n",
      "Epoch 145/175\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3630 - accuracy: 0.8734\n",
      "Epoch 146/175\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3623 - accuracy: 0.8740\n",
      "Epoch 147/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3617 - accuracy: 0.8737\n",
      "Epoch 148/175\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3613 - accuracy: 0.8741\n",
      "Epoch 149/175\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3612 - accuracy: 0.8737\n",
      "Epoch 150/175\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.3625 - accuracy: 0.8733\n",
      "Epoch 151/175\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3641 - accuracy: 0.8727\n",
      "Epoch 152/175\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3668 - accuracy: 0.8721\n",
      "Epoch 153/175\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3623 - accuracy: 0.8737\n",
      "Epoch 154/175\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.3571 - accuracy: 0.8759\n",
      "Epoch 155/175\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.3567 - accuracy: 0.8759\n",
      "Epoch 156/175\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3589 - accuracy: 0.8743\n",
      "Epoch 157/175\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3582 - accuracy: 0.8747\n",
      "Epoch 158/175\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3536 - accuracy: 0.8768\n",
      "Epoch 159/175\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.3541 - accuracy: 0.8761\n",
      "Epoch 160/175\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3563 - accuracy: 0.8757\n",
      "Epoch 161/175\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.3528 - accuracy: 0.8766\n",
      "Epoch 162/175\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.3510 - accuracy: 0.8777\n",
      "Epoch 163/175\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.3523 - accuracy: 0.8774\n",
      "Epoch 164/175\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.3512 - accuracy: 0.8770\n",
      "Epoch 165/175\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3490 - accuracy: 0.8789\n",
      "Epoch 166/175\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.3490 - accuracy: 0.8783\n",
      "Epoch 167/175\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.3493 - accuracy: 0.8778\n",
      "Epoch 168/175\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3477 - accuracy: 0.8788\n",
      "Epoch 169/175\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.3465 - accuracy: 0.8797\n",
      "Epoch 170/175\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.3468 - accuracy: 0.8788\n",
      "Epoch 171/175\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3462 - accuracy: 0.8793\n",
      "Epoch 172/175\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3447 - accuracy: 0.8799\n",
      "Epoch 173/175\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3444 - accuracy: 0.8797\n",
      "Epoch 174/175\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.3444 - accuracy: 0.8800\n",
      "Epoch 175/175\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.3433 - accuracy: 0.8805\n",
      "Execution time: 41.78900337219238 seconds\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "model_hm.fit(X_train_normalized, y_train, epochs = 175, verbose=1, callbacks=[CustomCallbackHM(),logger_hm_model], batch_size = X_train.shape[0]) \n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_hm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic opimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3995527923107147, 0.858299970626831]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wihtout_hm.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3986 - accuracy: 0.8616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3985791504383087, 0.8615999817848206]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hm.evaluate(X_test_normalized, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
