{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ2um3Oau3ET"
   },
   "source": [
    "<h2 style=\"color:blue\" align=\"center\">ResNet 50 on CIFAR</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dANJl4o8u3EY"
   },
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "P63KnoDvu3EY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import time, math \n",
    "\n",
    "from tensorflow import keras \n",
    "from keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Dense, Flatten, Conv2D, GlobalAveragePooling2D\n",
    "from keras.callbacks import Callback, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii6aMjDDu3Ea"
   },
   "source": [
    "#### Load and split the dataset into training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhGMMeWPu3Ea"
   },
   "source": [
    "CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wBeG5Puu3Eb",
    "outputId": "6b98ee93-94ae-46f7-fd11-10a733f84f55"
   },
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e04KvT7bu3Eb"
   },
   "source": [
    "CIFAR 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r1tq7jduu3Ec"
   },
   "outputs": [],
   "source": [
    "#(X_train,y_train),(X_test,y_test) = keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9gz-ukeu3Ec"
   },
   "source": [
    "#### Normalize the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "plStj22pu3Ed"
   },
   "outputs": [],
   "source": [
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZVL6i6rH2lmv"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Need to do upsampling\n",
    "https://www.kaggle.com/code/kutaykutlu/resnet50-transfer-learning-cifar-10-beginner/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czzweO3tu3Ee"
   },
   "source": [
    "#### Define ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "z75xiuVqu3Ef"
   },
   "outputs": [],
   "source": [
    "python_random.seed(3)\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(13)\n",
    "opti_name = ''\n",
    "\n",
    "def feature_scaling_up()\n",
    "def get_model(): \n",
    "    input_tensor = Input(shape=(32, 32, 3))\n",
    "    base_model = ResNet50(include_top=False, weights=None, input_tensor=input_tensor, input_shape=None)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dense(1024,activation = 'relu')(x) \n",
    "    # CIFAR 10\n",
    "    x = Dense(10,activation = 'softmax')(x) \n",
    "    # CIFAR 100\n",
    "    #x = Dense(10,activation = 'softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = base_model.input, outputs = Dense(1)(x))\n",
    "    \n",
    "    global opti_name    \n",
    "    # General SGD\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    #opti_name = 'SGD'\n",
    "    \n",
    "    # SGD with momentum\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01, momentum=0.6)\n",
    "    #opti_name = 'SGD with momentum'\n",
    "    \n",
    "    # SGD with Nesterov momentum \n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.01, momentum=0.6, nesterov=True)\n",
    "    #opti_name = 'SGD with Nesterov momentum'\n",
    "    \n",
    "    # RMSprop \n",
    "    #opti = keras.optimizers.RMSprop(learning_rate=0.001, momentum=0.6)\n",
    "    #opti_name = 'RMSprop'\n",
    "    \n",
    "    # Adam\n",
    "    opti = keras.optimizers.Adam(learning_rate=0.001) \n",
    "    opti_name = 'Adam'\n",
    "    \n",
    "    # Adamax\n",
    "    #opti = keras.optimizers.Adamax(learning_rate=0.001) \n",
    "    #opti_name = 'Adamax' \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = opti,\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f5rtWenu3Ef"
   },
   "source": [
    "#### Custom callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWo_NQOwu3Eg"
   },
   "source": [
    "For generic optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "U6OElGQtu3Eg"
   },
   "outputs": [],
   "source": [
    "# Get the best of base-line model and set it as stopping criteria in HM-based model\n",
    "generic_best = 0\n",
    "\n",
    "class CustomCallbackGeneric(Callback):   \n",
    "    # Training stop criteria\n",
    "    stop_at = 0.99\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global generic_best\n",
    "        acc = round(logs.get('accuracy'), 4)  \n",
    "        \n",
    "        if epoch == 0:\n",
    "            generic_best = acc             \n",
    "        \n",
    "        if epoch > 0 and acc > generic_best :\n",
    "            generic_best = acc  \n",
    "            \n",
    "        if(acc > self.stop_at):  \n",
    "            self.model.stop_training = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg30yzj-u3Eg"
   },
   "source": [
    "For HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "sfHN9hIdu3Eg"
   },
   "outputs": [],
   "source": [
    "class CustomCallbackHM(Callback):  \n",
    "    initial_weights = 0\n",
    "    previous_weights = 0\n",
    "    call_hm = 0 \n",
    "    r = 1\n",
    "    # r=0 no HM based, r=1 HM based\n",
    "     \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.initial_weights = model_hm.get_weights() \n",
    "        self.initial_weights = np.array(self.initial_weights,dtype=object)\n",
    "        self.previous_weights = self.initial_weights\n",
    "        # Harmonic mean based weights calculation\n",
    "        self.call_hm = np.vectorize(self.apply_hm)  \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Set the stopping criteria at (stop_at) the MAE obtained from the baseline model \n",
    "        global generic_best \n",
    "\n",
    "        current_weights = model_hm.get_weights() \n",
    "        current_weights = np.array(current_weights, dtype=object)       \n",
    "        \n",
    "        # First dense layer\n",
    "        tensor1 = tf.convert_to_tensor(self.initial_weights[177])\n",
    "        tensor2 = tf.convert_to_tensor(current_weights[177])\n",
    "        current_weights[177] = self.call_hm(tensor1, tensor2)\n",
    "        \n",
    "        # Second dense layer\n",
    "        tensor1 = tf.convert_to_tensor(self.initial_weights[178])\n",
    "        tensor2 = tf.convert_to_tensor(current_weights[178])\n",
    "        current_weights[178] = self.call_hm(tensor1, tensor2)  \n",
    "        \n",
    "        # Third dense layer\n",
    "        tensor1 = tf.convert_to_tensor(self.initial_weights[179])\n",
    "        tensor2 = tf.convert_to_tensor(current_weights[179])\n",
    "        current_weights[179] = self.call_hm(tensor1, tensor2)  \n",
    "               \n",
    "        # Updating the model with new weights   \n",
    "        model_hm.set_weights(current_weights.tolist())\n",
    "        self.previous_weights = current_weights\n",
    "        \n",
    "        # Stopping criteria\n",
    "        if(round(logs.get('accuracy'), 4) > generic_best): \n",
    "            self.model.stop_training = True\n",
    "        \n",
    "    def apply_hm(self, v1, v2):     \n",
    "        if v1==0 or v2==0:\n",
    "            return v2\n",
    "        elif v1>0 and v2>0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            min1 = min(v1,v2)\n",
    "            diff = abs(hm-min1) * self.r\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        elif v1<0 and v2<0:\n",
    "            hm = 2*v1*v2/(v1+v2)\n",
    "            max1 = max(v1,v2)\n",
    "            diff = abs(hm-max1) * self.r\n",
    "            if v2 > v1:\n",
    "                return v2 + diff\n",
    "            else:\n",
    "                return v2 - diff\n",
    "        else:\n",
    "            return v2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLpBFwlPu3Eh"
   },
   "source": [
    "To record loss and accuracy in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "L-v9BAOWu3Eh"
   },
   "outputs": [],
   "source": [
    "logger_generic_model = CSVLogger('3.Generic_ResNet_CIFAR.csv', append=False, separator=',')\n",
    "logger_hm_model = CSVLogger('3.HM_ResNet_CIFAR.csv', append=False, separator=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQK_pggku3Ei"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qp9HkB0Qtzp"
   },
   "source": [
    "Get a model to assign same weights to model with and without HM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZVjTunY_QoaX"
   },
   "outputs": [],
   "source": [
    "model = get_model() \n",
    "weights = model.get_weights() \n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62pnBX6bu3Ei"
   },
   "source": [
    "Generic opimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr3H0_aZu3Ej",
    "outputId": "28b20129-d951-48ad-af1d-8e2279403c54",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_wihtout_hm = get_model()\n",
    "model_wihtout_hm.set_weights(weights) \n",
    "st = time.time()\n",
    "model_wihtout_hm.fit(X_train_normalized, y_train, epochs = 1, verbose=1, callbacks=[CustomCallbackGeneric(), logger_generic_model], batch_size = X_train.shape[0]) \n",
    "et = time.time()\n",
    "elapsed_time = round(et - st, 4)\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "print('\\nGeneric optimizer best Accuracy is :', generic_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpwj5UDxu3Ej"
   },
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC_LxQAmu3Ek",
    "outputId": "c796e625-db30-4c9c-b654-cf726ea67c7d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5076 - accuracy: 0.4495\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1306 - accuracy: 0.5996\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9890 - accuracy: 0.6524\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8937 - accuracy: 0.6864\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8192 - accuracy: 0.7149\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7600 - accuracy: 0.7324\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7066 - accuracy: 0.7544\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6581 - accuracy: 0.7693\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6143 - accuracy: 0.7861\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5742 - accuracy: 0.7989\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5430 - accuracy: 0.8090\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5092 - accuracy: 0.8205\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4734 - accuracy: 0.8327\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4488 - accuracy: 0.8412\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4230 - accuracy: 0.8507\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3962 - accuracy: 0.8595\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3721 - accuracy: 0.8690\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3584 - accuracy: 0.8735\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3322 - accuracy: 0.8809\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3200 - accuracy: 0.8859\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2990 - accuracy: 0.8932\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2855 - accuracy: 0.8971\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2757 - accuracy: 0.9032\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2555 - accuracy: 0.9089\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2452 - accuracy: 0.9114\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2358 - accuracy: 0.9163\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2323 - accuracy: 0.9171\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2131 - accuracy: 0.9228\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2076 - accuracy: 0.9255\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1972 - accuracy: 0.9297\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1971 - accuracy: 0.9300\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1797 - accuracy: 0.9354\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1833 - accuracy: 0.9346\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1666 - accuracy: 0.9411\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1715 - accuracy: 0.9402\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1691 - accuracy: 0.9386\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1538 - accuracy: 0.9458\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1529 - accuracy: 0.9453\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1447 - accuracy: 0.9488\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1445 - accuracy: 0.9491\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1425 - accuracy: 0.9493\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1404 - accuracy: 0.9504\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1346 - accuracy: 0.9534\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1364 - accuracy: 0.9515\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1326 - accuracy: 0.9543\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1218 - accuracy: 0.9578\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1287 - accuracy: 0.9556\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1257 - accuracy: 0.9558\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1182 - accuracy: 0.9583\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1155 - accuracy: 0.9598\n",
      "Execution time: 290.2348153591156 seconds\n"
     ]
    }
   ],
   "source": [
    "model_hm = get_model()\n",
    "model_hm.set_weights(weights) \n",
    "st = time.time()\n",
    "model_hm.fit(X_train_normalized, y_train, epochs = num_epochs, verbose=1, callbacks=[CustomCallbackHM(),logger_hm_model], batch_size = X_train.shape[0]) \n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aly88iAou3Ek"
   },
   "source": [
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5k_wdQ5u3Ek",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_hm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic optimizer vs HM-based optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"3.Generic_ResNet_CIFAR.csv\")\n",
    "df2 = pd.read_csv(\"3.HM_ResNet_CIFAR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = range(0, df1.shape[0])\n",
    "x2 = range(0, df2.shape[0])\n",
    "y1 = df1['accuracy'] \n",
    "y2 = df2['accuracy']  \n",
    "plt.figure(figsize = (3,2), dpi = 200)\n",
    "plt.plot(x1, y1, \"r-\", label = opti_name, linewidth = 0.8, alpha = 0.7)\n",
    "plt.plot(x2, y2, \"k:\", label = 'HM-based ' + opti_name, linewidth = 1, alpha = 0.9) \n",
    "plt.ylabel('Accuracy' , fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xlabel('Epoch', fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "#plt.title(\"Loss\", fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.yticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.tight_layout()\n",
    "plt.legend(prop={'size': 5})\n",
    "#plt.savefig(\"graph.png\",bbox_inches='tight',dpi=(300)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = range(0, df1.shape[0])\n",
    "x2 = range(0, df2.shape[0])\n",
    "y1 = df1['loss'] \n",
    "y2 = df2['loss']  \n",
    "plt.figure(figsize = (3,2), dpi = 200)\n",
    "plt.plot(x1, y1, \"r-\", label = opti_name, linewidth = 0.8, alpha = 0.7)\n",
    "plt.plot(x2, y2, \"k:\", label = 'HM-based ' + opti_name, linewidth = 1, alpha = 0.9) \n",
    "plt.ylabel('Loss' , fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xlabel('Epoch', fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "#plt.title(\"MAE\", fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.yticks(fontsize = 7, fontname = 'Times New Roman')\n",
    "plt.tight_layout()\n",
    "plt.legend(prop={'size': 5})\n",
    "#plt.savefig(\"graph.png\",bbox_inches='tight',dpi=(300)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiCK5k2Bu3Ek"
   },
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB6FS5Hpu3Ek"
   },
   "source": [
    "Generic opimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1HMuXLPu3El",
    "outputId": "37c7e3d3-f49c-4bba-ba22-06fa7d547a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.6716 - accuracy: 0.6649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.671616554260254, 0.664900004863739]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wihtout_hm.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k53-C48xu3El"
   },
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyuXtuC9u3El",
    "outputId": "cc130b40-bed9-43c5-bb08-400e8fbd1d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.9155 - accuracy: 0.6532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.915454149246216, 0.6531999707221985]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hm.evaluate(X_test_normalized, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR-10.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
