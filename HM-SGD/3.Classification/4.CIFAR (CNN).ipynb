{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ2um3Oau3ET"
   },
   "source": [
    "<h2 style=\"color:blue\" align=\"center\">Convolutional Neural Network (CNN) on CIFAR</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dANJl4o8u3EY"
   },
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P63KnoDvu3EY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 18:24:00.366439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 18:24:02.026804: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import time, math \n",
    "\n",
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D \n",
    "from keras.callbacks import Callback, CSVLogger\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reserve memory for the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 18:24:26.149282: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 18:24:31.406254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1621 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii6aMjDDu3Ea"
   },
   "source": [
    "#### Load and split the dataset into training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhGMMeWPu3Ea"
   },
   "source": [
    "CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1wBeG5Puu3Eb"
   },
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e04KvT7bu3Eb"
   },
   "source": [
    "CIFAR 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r1tq7jduu3Ec"
   },
   "outputs": [],
   "source": [
    "#(X_train,y_train),(X_test,y_test) = keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PDgUz0F5obY"
   },
   "source": [
    "Here we see there are 50000 training images and 1000 test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9gz-ukeu3Ec"
   },
   "source": [
    "#### Normalize the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "plStj22pu3Ed"
   },
   "outputs": [],
   "source": [
    "X_train_normalized = X_train / 255.0\n",
    "X_test_normalized = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czzweO3tu3Ee"
   },
   "source": [
    "#### Define DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "z75xiuVqu3Ef"
   },
   "outputs": [],
   "source": [
    "python_random.seed(7)\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "opti_name = ''\n",
    "\n",
    "def get_model(): \n",
    "    model = Sequential([\n",
    "        # CNN layers\n",
    "        Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", input_shape=(32,32,3)),\n",
    "        MaxPooling2D((2,2)),        \n",
    "        Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"),\n",
    "        MaxPooling2D((2,2)),\n",
    "        \n",
    "        # Dense layer\n",
    "        Flatten(),\n",
    "        Dense(128, activation = 'relu'),  \n",
    "        # For CIFAR-10\n",
    "        Dense(10, activation = 'softmax')\n",
    "        # For CIFAR-100\n",
    "        #Dense(100, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    global opti_name\n",
    "    \n",
    "    # General SGD\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.001)\n",
    "    #opti_name = 'SGD'\n",
    "    \n",
    "    # SGD with momentum\n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.001, momentum=0.4)\n",
    "    #opti_name = 'SGD with momentum'\n",
    "    \n",
    "    # SGD with Nesterov momentum \n",
    "    #opti = keras.optimizers.SGD(learning_rate=0.001, momentum=0.4, nesterov=True)\n",
    "    #opti_name = 'SGD with Nesterov momentum'\n",
    "    \n",
    "    # RMSprop \n",
    "    #opti = keras.optimizers.RMSprop(learning_rate=0.001, momentum=0.4)\n",
    "    #opti_name = 'RMSprop'\n",
    "    \n",
    "    # Adam\n",
    "    opti = keras.optimizers.Adam(learning_rate=0.001) \n",
    "    opti_name = 'Adam'\n",
    "    \n",
    "    # Adamax\n",
    "    #opti = keras.optimizers.Adamax(learning_rate=0.001) \n",
    "    #opti_name = 'Adamax' \n",
    "    \n",
    "    # Nadam\n",
    "    #opti = keras.optimizers.Nadam(learning_rate=0.001) \n",
    "    #opti_name = 'Nadam'  \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer = opti,\n",
    "        loss = 'categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f5rtWenu3Ef"
   },
   "source": [
    "#### Custom callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWo_NQOwu3Eg"
   },
   "source": [
    "For generic optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "U6OElGQtu3Eg"
   },
   "outputs": [],
   "source": [
    "# Get the best of base-line model and set it as stopping criteria in HM-based model\n",
    "generic_best = 0\n",
    "\n",
    "class CustomCallbackGeneric(Callback):  \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        global generic_best\n",
    "        accuracy = round(logs.get('accuracy'), 4) \n",
    "        \n",
    "        if epoch == 0:\n",
    "            generic_best = accuracy     \n",
    "        \n",
    "        if epoch > 0 and accuracy < generic_best :\n",
    "            generic_best = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg30yzj-u3Eg"
   },
   "source": [
    "For HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sfHN9hIdu3Eg"
   },
   "outputs": [],
   "source": [
    "class CustomCallbackHM(Callback):  \n",
    "    initial_weights = 0\n",
    "    previous_weights = 0\n",
    "    call_hm = 0    \n",
    "     \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.initial_weights = model_hm.get_weights() \n",
    "        self.initial_weights = np.array(self.initial_weights,dtype=object)\n",
    "        self.previous_weights = self.initial_weights\n",
    "        # Harmonic mean based weights calculation\n",
    "        self.call_hm = np.vectorize(self.apply_hm)  \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "         # Set the stopping criteria at (stop_at) the MAE obtained from the baseline model \n",
    "        global generic_best \n",
    "        \n",
    "        num_layers = len(model_hm.layers)  \n",
    "        current_weights = model_hm.get_weights()\n",
    "        current_weights = np.array(current_weights,dtype=object)        \n",
    "\n",
    "        for i in range(len(current_weights)):  \n",
    "            # Harmonic mean based weights calculation\n",
    "            tensor1 = tf.convert_to_tensor(self.previous_weights[i])\n",
    "            tensor2 = tf.convert_to_tensor(current_weights[i])\n",
    "            current_weights[i] = self.call_hm(tensor1, tensor2, epoch)   \n",
    "            \n",
    "        # Updating the model with new weights\n",
    "        model_hm.set_weights(current_weights.tolist())\n",
    "        self.previous_weights = current_weights \n",
    "        \n",
    "        #Stopping criteria\n",
    "        #if(round(logs.get('accuracy'), 4) < generic_best):  \n",
    "            #self.model.stop_training = True\n",
    "        \n",
    "    def apply_hm(self, v1, v2, epoch):  \n",
    "        r = 0\n",
    "        if epoch < 50:\n",
    "            r = 1\n",
    "        elif epoch > 50 and epoch < 100:\n",
    "            r = 0.75\n",
    "        elif epoch > 100 and epoch < 150:\n",
    "            r = 0.5\n",
    "        else:  \n",
    "            r = 0.25 \n",
    "            \n",
    "        if v1==0 or v2==0:\n",
    "            return v2\n",
    "        elif v1 > v2:\n",
    "            t1 = abs(v1)\n",
    "            t2 = abs(v2)\n",
    "            hm = 2*t1*t2/(t1+t2)\n",
    "            min1 = min(t1,t2)\n",
    "            diff = abs(hm-min1) * r \n",
    "            v2 = v2 - diff\n",
    "            return v2  \n",
    "        elif v1 < v2:\n",
    "            t1 = abs(v1)\n",
    "            t2 = abs(v2)\n",
    "            hm = 2*t1*t2/(t1+t2)\n",
    "            min1 = min(t1,t2)\n",
    "            diff = abs(hm-min1) * r \n",
    "            v2 = v2 + diff\n",
    "            return v2   \n",
    "        else:\n",
    "            return v2   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQK_pggku3Ei"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62pnBX6bu3Ei"
   },
   "source": [
    "Generic opimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sr3H0_aZu3Ej",
    "outputId": "fba700c7-daa9-4eef-cba3-c4586325a003",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model() \n",
    "weights = model.get_weights() \n",
    "num_epochs = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLpBFwlPu3Eh"
   },
   "source": [
    "To record loss and accuracy in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L-v9BAOWu3Eh"
   },
   "outputs": [],
   "source": [
    "generic_file = '5.CIFAR (CNN)'+opti_name+' optimizer.csv'\n",
    "hm_file = '5.CIFAR (CNN)'+opti_name+' HM-based optimizer.csv' \n",
    "logger_generic_model = CSVLogger(generic_file, append = False, separator=',')\n",
    "logger_hm_model = CSVLogger(hm_file, append = False, separator=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 18:24:55.074221: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-10-15 18:24:57.996666: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-15 18:24:58.012786: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-15 18:24:58.012893: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-10-15 18:24:58.014371: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-10-15 18:24:58.014629: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-10-15 18:24:58.196931: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 4ms/step - loss: 1.6398 - accuracy: 0.4136\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2965 - accuracy: 0.5405\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1709 - accuracy: 0.5884\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0805 - accuracy: 0.6236\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0143 - accuracy: 0.6474\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.9545 - accuracy: 0.6688\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.9030 - accuracy: 0.6878\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.8569 - accuracy: 0.7050\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.8101 - accuracy: 0.7200\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.7812 - accuracy: 0.7284\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.7429 - accuracy: 0.7445\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.7034 - accuracy: 0.7567\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.6820 - accuracy: 0.7652\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.6451 - accuracy: 0.7773\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.6076 - accuracy: 0.7907\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.5746 - accuracy: 0.8032\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.8112\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.5182 - accuracy: 0.8223\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.8334\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.4640 - accuracy: 0.8411\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.4230 - accuracy: 0.8577\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.4000 - accuracy: 0.8652\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8731\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.3499 - accuracy: 0.8832\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.3175 - accuracy: 0.8950\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2748 - accuracy: 0.9096\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2489 - accuracy: 0.9199\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2313 - accuracy: 0.9244\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.2053 - accuracy: 0.9354\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1862 - accuracy: 0.9406\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1648 - accuracy: 0.9496\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1531 - accuracy: 0.9530\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1375 - accuracy: 0.9589\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1233 - accuracy: 0.9634\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1024 - accuracy: 0.9717\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9708\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9736\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0765 - accuracy: 0.9798\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0633 - accuracy: 0.9844\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9800\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9871\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9844\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9880\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9936\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0497 - accuracy: 0.9864\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9669\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9770\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9923\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9985\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9996\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9999\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9998\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9926\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1736 - accuracy: 0.9397\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9806\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0248 - accuracy: 0.9938\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9993\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9999\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9999\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9501\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9574\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.9799\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9930\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9986\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9999\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 9.9535e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 9.0395e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 8.2855e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 7.4965e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 1s 3ms/step - loss: 6.8036e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 6.2767e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 6.0648e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 5.3777e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 4.9784e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 4.6206e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 3.9324e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 3.5756e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 3.2757e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 2.9779e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 2.7503e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.3471 - accuracy: 0.9187\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.1487 - accuracy: 0.9474\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9920\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Execution time: 66.6681 seconds\n"
     ]
    }
   ],
   "source": [
    "model_wihtout_hm = get_model()\n",
    "model_wihtout_hm.set_weights(weights) \n",
    "st = time.time() \n",
    "model_wihtout_hm.fit(X_train_normalized, y_train, epochs = num_epochs, verbose=1, callbacks=[CustomCallbackGeneric(), logger_generic_model], batch_size=batch_size) \n",
    "et = time.time()\n",
    "elapsed_training_time_generic = round(et - st, 4)\n",
    "print('Execution time:', elapsed_training_time_generic, 'seconds') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpwj5UDxu3Ej"
   },
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC_LxQAmu3Ek",
    "outputId": "959ad653-1cc0-4331-964c-f7a26c8a8c89",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 18:27:55.997968: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 585.94MiB (rounded to 614400000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-10-15 18:27:55.998053: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2022-10-15 18:27:55.998079: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 59, Chunks in use: 58. 14.8KiB allocated for chunks. 14.5KiB in use in bin. 3.1KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998093: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 7, Chunks in use: 7. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.5KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998105: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998119: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 4, Chunks in use: 3. 13.2KiB allocated for chunks. 10.5KiB in use in bin. 10.1KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998132: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 11, Chunks in use: 10. 56.8KiB allocated for chunks. 51.8KiB in use in bin. 43.5KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998145: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998159: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998170: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998213: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 216.0KiB allocated for chunks. 216.0KiB in use in bin. 216.0KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998228: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 4, Chunks in use: 4. 530.5KiB allocated for chunks. 530.5KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998239: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998251: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 536.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998266: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 9, Chunks in use: 8. 12.65MiB allocated for chunks. 11.53MiB in use in bin. 9.78MiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998277: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998288: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998298: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998309: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998341: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998352: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998362: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998376: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 1.00GiB allocated for chunks. 585.94MiB in use in bin. 585.94MiB client-requested in use in bin.\n",
      "2022-10-15 18:27:55.998389: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 585.94MiB was 256.00MiB, Chunk State: \n",
      "2022-10-15 18:27:55.998413: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 438.06MiB | Requested Size: 1.12MiB | in_use: 0 | bin_num: 20, prev:   Size: 585.94MiB | Requested Size: 585.94MiB | in_use: 1 | bin_num: -1\n",
      "2022-10-15 18:27:55.998423: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 1073741824\n",
      "2022-10-15 18:27:55.998436: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9812000000 of size 614400000 next 39\n",
      "2022-10-15 18:27:55.998446: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f98369f0000 of size 459341824 next 18446744073709551615\n",
      "2022-10-15 18:27:55.998457: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 8388608\n",
      "2022-10-15 18:27:55.998467: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f992e000000 of size 2000128 next 28\n",
      "2022-10-15 18:27:55.998476: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f992e1e8500 of size 1179648 next 57\n",
      "2022-10-15 18:27:55.998486: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f992e308500 of size 1179648 next 61\n",
      "2022-10-15 18:27:55.998494: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f992e428500 of size 1179648 next 95\n",
      "2022-10-15 18:27:55.998503: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f992e548500 of size 1179648 next 85\n",
      "2022-10-15 18:27:55.998512: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f992e668500 of size 1669888 next 18446744073709551615\n",
      "2022-10-15 18:27:55.998521: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 2097152\n",
      "2022-10-15 18:27:55.998530: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600000 of size 256 next 1\n",
      "2022-10-15 18:27:55.998539: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600100 of size 1280 next 2\n",
      "2022-10-15 18:27:55.998548: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600600 of size 256 next 3\n",
      "2022-10-15 18:27:55.998557: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600700 of size 256 next 4\n",
      "2022-10-15 18:27:55.998565: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600800 of size 256 next 6\n",
      "2022-10-15 18:27:55.998573: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600900 of size 256 next 7\n",
      "2022-10-15 18:27:55.998581: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600a00 of size 256 next 5\n",
      "2022-10-15 18:27:55.998590: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600b00 of size 256 next 8\n",
      "2022-10-15 18:27:55.998598: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600c00 of size 256 next 13\n",
      "2022-10-15 18:27:55.998607: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600d00 of size 256 next 11\n",
      "2022-10-15 18:27:55.998617: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600e00 of size 256 next 12\n",
      "2022-10-15 18:27:55.998626: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991600f00 of size 512 next 16\n",
      "2022-10-15 18:27:55.998635: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991601100 of size 256 next 17\n",
      "2022-10-15 18:27:55.998643: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991601200 of size 256 next 21\n",
      "2022-10-15 18:27:55.998651: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991601300 of size 256 next 24\n",
      "2022-10-15 18:27:55.998660: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991601400 of size 256 next 22\n",
      "2022-10-15 18:27:55.998668: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991601500 of size 256 next 23\n",
      "2022-10-15 18:27:55.998676: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991601600 of size 256 next 27\n",
      "2022-10-15 18:27:55.998685: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991601700 of size 4096 next 9\n",
      "2022-10-15 18:27:55.998697: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991602700 of size 3584 next 10\n",
      "2022-10-15 18:27:55.998705: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603500 of size 256 next 29\n",
      "2022-10-15 18:27:55.998714: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603600 of size 256 next 40\n",
      "2022-10-15 18:27:55.998722: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603700 of size 256 next 33\n",
      "2022-10-15 18:27:55.998730: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603800 of size 256 next 32\n",
      "2022-10-15 18:27:55.998739: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603900 of size 256 next 38\n",
      "2022-10-15 18:27:55.998747: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603a00 of size 256 next 82\n",
      "2022-10-15 18:27:55.998755: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603b00 of size 256 next 37\n",
      "2022-10-15 18:27:55.998763: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603c00 of size 256 next 31\n",
      "2022-10-15 18:27:55.998772: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603d00 of size 512 next 36\n",
      "2022-10-15 18:27:55.998781: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991603f00 of size 7680 next 26\n",
      "2022-10-15 18:27:55.998790: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991605d00 of size 5120 next 25\n",
      "2022-10-15 18:27:55.998799: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991607100 of size 132096 next 15\n",
      "2022-10-15 18:27:55.998808: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991627500 of size 73728 next 14\n",
      "2022-10-15 18:27:55.998818: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991639500 of size 1862400 next 18446744073709551615\n",
      "2022-10-15 18:27:55.998826: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 4194304\n",
      "2022-10-15 18:27:55.998835: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a00000 of size 256 next 41\n",
      "2022-10-15 18:27:55.998844: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a00100 of size 256 next 42\n",
      "2022-10-15 18:27:55.998852: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a00200 of size 256 next 43\n",
      "2022-10-15 18:27:55.998861: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a00300 of size 256 next 44\n",
      "2022-10-15 18:27:55.998869: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a00400 of size 256 next 45\n",
      "2022-10-15 18:27:55.998878: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a00500 of size 3584 next 46\n",
      "2022-10-15 18:27:55.998886: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a01300 of size 256 next 47\n",
      "2022-10-15 18:27:55.998896: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a01400 of size 73728 next 48\n",
      "2022-10-15 18:27:55.998905: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a13400 of size 256 next 49\n",
      "2022-10-15 18:27:55.998913: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a13500 of size 512 next 50\n",
      "2022-10-15 18:27:55.998922: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a13700 of size 5120 next 51\n",
      "2022-10-15 18:27:55.998930: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a14b00 of size 256 next 52\n",
      "2022-10-15 18:27:55.998939: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a14c00 of size 3584 next 53\n",
      "2022-10-15 18:27:55.998947: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a15a00 of size 256 next 54\n",
      "2022-10-15 18:27:55.998956: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a15b00 of size 73728 next 55\n",
      "2022-10-15 18:27:55.998964: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a27b00 of size 256 next 56\n",
      "2022-10-15 18:27:55.998972: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a27c00 of size 512 next 58\n",
      "2022-10-15 18:27:55.998981: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a27e00 of size 5120 next 59\n",
      "2022-10-15 18:27:55.998989: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29200 of size 256 next 60\n",
      "2022-10-15 18:27:55.998997: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29300 of size 256 next 86\n",
      "2022-10-15 18:27:55.999006: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29400 of size 256 next 62\n",
      "2022-10-15 18:27:55.999014: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29500 of size 256 next 63\n",
      "2022-10-15 18:27:55.999022: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29600 of size 256 next 64\n",
      "2022-10-15 18:27:55.999030: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29700 of size 256 next 65\n",
      "2022-10-15 18:27:55.999039: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29800 of size 256 next 66\n",
      "2022-10-15 18:27:55.999047: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29900 of size 256 next 67\n",
      "2022-10-15 18:27:55.999055: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29a00 of size 256 next 69\n",
      "2022-10-15 18:27:55.999063: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29b00 of size 256 next 70\n",
      "2022-10-15 18:27:55.999072: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29c00 of size 256 next 83\n",
      "2022-10-15 18:27:55.999080: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29d00 of size 256 next 75\n",
      "2022-10-15 18:27:55.999088: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29e00 of size 256 next 68\n",
      "2022-10-15 18:27:55.999097: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a29f00 of size 512 next 78\n",
      "2022-10-15 18:27:55.999105: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2a100 of size 5120 next 88\n",
      "2022-10-15 18:27:55.999113: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2b500 of size 256 next 73\n",
      "2022-10-15 18:27:55.999122: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9991a2b600 of size 256 next 76\n",
      "2022-10-15 18:27:55.999130: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2b700 of size 256 next 92\n",
      "2022-10-15 18:27:55.999138: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2b800 of size 256 next 72\n",
      "2022-10-15 18:27:55.999147: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2b900 of size 6144 next 80\n",
      "2022-10-15 18:27:55.999156: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2d100 of size 256 next 84\n",
      "2022-10-15 18:27:55.999166: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2d200 of size 256 next 79\n",
      "2022-10-15 18:27:55.999174: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2d300 of size 256 next 81\n",
      "2022-10-15 18:27:55.999182: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2d400 of size 256 next 91\n",
      "2022-10-15 18:27:55.999191: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2d500 of size 4608 next 71\n",
      "2022-10-15 18:27:55.999202: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2e700 of size 5120 next 89\n",
      "2022-10-15 18:27:55.999212: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a2fb00 of size 136960 next 74\n",
      "2022-10-15 18:27:55.999220: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a51200 of size 256 next 90\n",
      "2022-10-15 18:27:55.999228: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a51300 of size 512 next 77\n",
      "2022-10-15 18:27:55.999237: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a51500 of size 9472 next 34\n",
      "2022-10-15 18:27:55.999246: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a53a00 of size 137216 next 87\n",
      "2022-10-15 18:27:55.999255: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a75200 of size 256 next 102\n",
      "2022-10-15 18:27:55.999264: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a75300 of size 512 next 98\n",
      "2022-10-15 18:27:55.999272: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9991a75500 of size 2816 next 94\n",
      "2022-10-15 18:27:55.999280: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a76000 of size 256 next 93\n",
      "2022-10-15 18:27:55.999289: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a76100 of size 256 next 99\n",
      "2022-10-15 18:27:55.999298: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a76200 of size 4864 next 100\n",
      "2022-10-15 18:27:55.999306: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9991a77500 of size 5120 next 101\n",
      "2022-10-15 18:27:55.999315: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991a78900 of size 136960 next 96\n",
      "2022-10-15 18:27:55.999323: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f9991a9a000 of size 548864 next 20\n",
      "2022-10-15 18:27:55.999332: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991b20000 of size 1179648 next 18\n",
      "2022-10-15 18:27:55.999341: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f9991c40000 of size 1835008 next 18446744073709551615\n",
      "2022-10-15 18:27:55.999349: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2022-10-15 18:27:55.999362: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 58 Chunks of size 256 totalling 14.5KiB\n",
      "2022-10-15 18:27:55.999373: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 7 Chunks of size 512 totalling 3.5KiB\n",
      "2022-10-15 18:27:55.999382: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-10-15 18:27:55.999393: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 3584 totalling 10.5KiB\n",
      "2022-10-15 18:27:55.999402: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 4096 totalling 4.0KiB\n",
      "2022-10-15 18:27:55.999412: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 4608 totalling 4.5KiB\n",
      "2022-10-15 18:27:55.999422: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 4864 totalling 4.8KiB\n",
      "2022-10-15 18:27:55.999432: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 5 Chunks of size 5120 totalling 25.0KiB\n",
      "2022-10-15 18:27:55.999442: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 6144 totalling 6.0KiB\n",
      "2022-10-15 18:27:55.999451: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 7680 totalling 7.5KiB\n",
      "2022-10-15 18:27:55.999462: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 9472 totalling 9.2KiB\n",
      "2022-10-15 18:27:55.999473: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 73728 totalling 216.0KiB\n",
      "2022-10-15 18:27:55.999483: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 132096 totalling 129.0KiB\n",
      "2022-10-15 18:27:55.999493: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 136960 totalling 267.5KiB\n",
      "2022-10-15 18:27:55.999503: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 137216 totalling 134.0KiB\n",
      "2022-10-15 18:27:55.999513: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 4 Chunks of size 1179648 totalling 4.50MiB\n",
      "2022-10-15 18:27:55.999523: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1669888 totalling 1.59MiB\n",
      "2022-10-15 18:27:55.999532: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1835008 totalling 1.75MiB\n",
      "2022-10-15 18:27:55.999542: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1862400 totalling 1.78MiB\n",
      "2022-10-15 18:27:55.999552: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2000128 totalling 1.91MiB\n",
      "2022-10-15 18:27:55.999562: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 614400000 totalling 585.94MiB\n",
      "2022-10-15 18:27:55.999572: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 598.28MiB\n",
      "2022-10-15 18:27:55.999582: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 1088421888 memory_limit_: 1700134912 available bytes: 611713024 curr_region_allocation_bytes_: 1073741824\n",
      "2022-10-15 18:27:55.999601: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                      1700134912\n",
      "InUse:                       627343360\n",
      "MaxInUse:                    911835136\n",
      "NumAllocs:                     1196377\n",
      "MaxAllocSize:                614400000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-10-15 18:27:55.999622: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *********************************************************_________________________________________**\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_hm\u001b[38;5;241m.\u001b[39mset_weights(weights) \n\u001b[1;32m      3\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel_hm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mCustomCallbackHM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlogger_hm_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      5\u001b[0m et \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m elapsed_training_time_hm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(et \u001b[38;5;241m-\u001b[39m st, \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model_hm = get_model()\n",
    "model_hm.set_weights(weights) \n",
    "st = time.time()\n",
    "model_hm.fit(X_train_normalized, y_train, epochs = num_epochs, verbose=1, callbacks=[CustomCallbackHM(),logger_hm_model], batch_size=batch_size) \n",
    "et = time.time()\n",
    "elapsed_training_time_hm = round(et - st, 4)\n",
    "print('Execution time:', elapsed_training_time_hm, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aly88iAou3Ek"
   },
   "source": [
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5k_wdQ5u3Ek",
    "outputId": "d2a82c48-0b4f-433b-a3ea-e08e61e5db47",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_hm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic optimizer vs HM-based optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(generic_file)\n",
    "df2 = pd.read_csv(hm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = range(0, df1.shape[0])\n",
    "x2 = range(0, df2.shape[0])\n",
    "y1 = df1['accuracy'] \n",
    "y2 = df2['accuracy']  \n",
    "plt.figure(figsize = (3,2), dpi = 200)\n",
    "plt.plot(x1, y1, \"r-\", label = opti_name, linewidth = 0.8, alpha = 0.7)\n",
    "plt.plot(x2, y2, \"k:\", label = 'HM-based ' + opti_name, linewidth = 1, alpha = 0.9) \n",
    "plt.ylabel('Accuracy' , fontdict = {'fontsize':5})\n",
    "plt.xlabel('Epoch', fontdict = {'fontsize':5}) \n",
    "#plt.title(\"Loss\", fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xticks(fontsize = 5)\n",
    "plt.yticks(fontsize = 5)\n",
    "plt.tight_layout()\n",
    "plt.legend(prop={'size': 5})\n",
    "#plt.savefig(\"graph.png\",bbox_inches='tight',dpi=(300)) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = range(0, df1.shape[0])\n",
    "x2 = range(0, df2.shape[0])\n",
    "y1 = df1['loss'] \n",
    "y2 = df2['loss']   \n",
    "plt.figure(figsize = (3,2), dpi = 200)\n",
    "plt.plot(x1, y1, \"r-\", label = opti_name, linewidth = 0.8, alpha = 0.7)\n",
    "plt.plot(x2, y2, \"k:\", label = 'HM-based ' + opti_name, linewidth = 1, alpha = 0.9) \n",
    "plt.ylabel('Loss' , fontdict = {'fontsize':5})\n",
    "plt.xlabel('Epoch', fontdict = {'fontsize':5}) \n",
    "#plt.title(\"Loss\", fontdict = {'fontname':'Times New Roman', 'fontsize':8})\n",
    "plt.xticks(fontsize = 5)\n",
    "plt.yticks(fontsize = 5)\n",
    "plt.tight_layout()\n",
    "plt.legend(prop={'size': 5})\n",
    "#plt.savefig(\"graph.png\",bbox_inches='tight',dpi=(300)) \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiCK5k2Bu3Ek"
   },
   "source": [
    "###### Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB6FS5Hpu3Ek"
   },
   "source": [
    "Generic opimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1HMuXLPu3El",
    "outputId": "5cb866ab-a89d-4c87-95d4-fcfb797cd8e3"
   },
   "outputs": [],
   "source": [
    "model_wihtout_hm.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k53-C48xu3El"
   },
   "source": [
    "HM based optimizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyuXtuC9u3El",
    "outputId": "e5420f46-e500-4118-cabd-42e64da4c751"
   },
   "outputs": [],
   "source": [
    "model_hm.evaluate(X_test_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Release the GPU memory"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CIFAR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
